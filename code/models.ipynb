{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_featureV1.csv')\n",
    "test = pd.read_csv('../data/test_featureV2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "      <th>voice_talk_time_count</th>\n",
       "      <th>voice_talk_time_std</th>\n",
       "      <th>voice_talk_time_max</th>\n",
       "      <th>voice_talk_time_min</th>\n",
       "      <th>voice_talk_time_median</th>\n",
       "      <th>voice_talk_time_mean</th>\n",
       "      <th>voice_talk_time_sum</th>\n",
       "      <th>voice_opp_num_unique_count</th>\n",
       "      <th>...</th>\n",
       "      <th>wa_up_flow_min</th>\n",
       "      <th>wa_up_flow_median</th>\n",
       "      <th>wa_up_flow_mean</th>\n",
       "      <th>wa_up_flow_sum</th>\n",
       "      <th>wa_down_flow_std</th>\n",
       "      <th>wa_down_flow_max</th>\n",
       "      <th>wa_down_flow_min</th>\n",
       "      <th>wa_down_flow_median</th>\n",
       "      <th>wa_down_flow_mean</th>\n",
       "      <th>wa_down_flow_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1877</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>471.857934</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>192.923077</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>88103.394619</td>\n",
       "      <td>3.929411e+07</td>\n",
       "      <td>7.238801e+06</td>\n",
       "      <td>1.141611e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15610.0</td>\n",
       "      <td>1.123536e+06</td>\n",
       "      <td>5.010969e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u1332</td>\n",
       "      <td>0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>124.877918</td>\n",
       "      <td>784.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>97.465517</td>\n",
       "      <td>11306.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>428466.830087</td>\n",
       "      <td>6.379871e+08</td>\n",
       "      <td>4.804560e+06</td>\n",
       "      <td>1.388108e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5477.0</td>\n",
       "      <td>6.544100e+05</td>\n",
       "      <td>9.744165e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2758</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>35.422205</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.590361</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>25311.213270</td>\n",
       "      <td>5.340666e+06</td>\n",
       "      <td>3.427026e+05</td>\n",
       "      <td>4.498169e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5469.0</td>\n",
       "      <td>7.510883e+04</td>\n",
       "      <td>1.584796e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u4601</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>92.632762</td>\n",
       "      <td>376.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.600000</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6283.0</td>\n",
       "      <td>326201.416667</td>\n",
       "      <td>1.096037e+08</td>\n",
       "      <td>1.027373e+07</td>\n",
       "      <td>1.329986e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8045.0</td>\n",
       "      <td>1.345599e+06</td>\n",
       "      <td>4.521212e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0795</td>\n",
       "      <td>0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>151.221809</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>127.316129</td>\n",
       "      <td>98670.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2224.5</td>\n",
       "      <td>35094.644788</td>\n",
       "      <td>1.817903e+07</td>\n",
       "      <td>8.740399e+05</td>\n",
       "      <td>1.561364e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2673.5</td>\n",
       "      <td>1.830555e+05</td>\n",
       "      <td>9.482274e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u1953</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.222549</td>\n",
       "      <td>207.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.533333</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8266.5</td>\n",
       "      <td>154972.211679</td>\n",
       "      <td>8.492477e+07</td>\n",
       "      <td>2.235862e+07</td>\n",
       "      <td>3.975613e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13036.0</td>\n",
       "      <td>2.459291e+06</td>\n",
       "      <td>1.347691e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u1639</td>\n",
       "      <td>0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>54.262087</td>\n",
       "      <td>398.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>57.371069</td>\n",
       "      <td>9122.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7603.0</td>\n",
       "      <td>218984.805004</td>\n",
       "      <td>2.976004e+08</td>\n",
       "      <td>1.257740e+07</td>\n",
       "      <td>2.485892e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14227.0</td>\n",
       "      <td>2.275916e+06</td>\n",
       "      <td>3.092970e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u3519</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>195346.600000</td>\n",
       "      <td>2.930199e+06</td>\n",
       "      <td>1.030225e+07</td>\n",
       "      <td>3.994208e+07</td>\n",
       "      <td>111.0</td>\n",
       "      <td>8767.0</td>\n",
       "      <td>2.703492e+06</td>\n",
       "      <td>4.055238e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0210</td>\n",
       "      <td>0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>187.812419</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>140.423948</td>\n",
       "      <td>43391.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5301.0</td>\n",
       "      <td>56508.643529</td>\n",
       "      <td>7.815145e+07</td>\n",
       "      <td>2.293714e+06</td>\n",
       "      <td>5.452587e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8060.0</td>\n",
       "      <td>3.100945e+05</td>\n",
       "      <td>4.288607e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u1153</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.887271</td>\n",
       "      <td>141.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7376.5</td>\n",
       "      <td>298102.033333</td>\n",
       "      <td>1.788612e+07</td>\n",
       "      <td>8.089902e+06</td>\n",
       "      <td>4.456530e+07</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10064.0</td>\n",
       "      <td>2.277784e+06</td>\n",
       "      <td>1.366671e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>u3578</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>128.915607</td>\n",
       "      <td>574.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.185185</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u0247</td>\n",
       "      <td>0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>73.500461</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>61.573508</td>\n",
       "      <td>42301.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8365.0</td>\n",
       "      <td>186211.083449</td>\n",
       "      <td>2.677715e+08</td>\n",
       "      <td>3.541292e+06</td>\n",
       "      <td>5.048560e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12237.0</td>\n",
       "      <td>9.049267e+05</td>\n",
       "      <td>1.301285e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>u0930</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>186.676190</td>\n",
       "      <td>278.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11064.5</td>\n",
       "      <td>48697.045652</td>\n",
       "      <td>2.240064e+07</td>\n",
       "      <td>1.659858e+06</td>\n",
       "      <td>2.565724e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15220.5</td>\n",
       "      <td>2.055417e+05</td>\n",
       "      <td>9.454916e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>u0800</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>196.110581</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>91.792453</td>\n",
       "      <td>4865.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6368.0</td>\n",
       "      <td>80359.508475</td>\n",
       "      <td>1.896484e+07</td>\n",
       "      <td>7.178760e+05</td>\n",
       "      <td>8.251934e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9491.0</td>\n",
       "      <td>1.804563e+05</td>\n",
       "      <td>4.258769e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>u3910</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>155.363892</td>\n",
       "      <td>919.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>89.217949</td>\n",
       "      <td>6959.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15618.0</td>\n",
       "      <td>624616.821692</td>\n",
       "      <td>1.779533e+09</td>\n",
       "      <td>4.532703e+07</td>\n",
       "      <td>1.319733e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37942.0</td>\n",
       "      <td>5.317942e+06</td>\n",
       "      <td>1.515082e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>u0122</td>\n",
       "      <td>0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>234.223060</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>96.067736</td>\n",
       "      <td>53894.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7479.0</td>\n",
       "      <td>110001.562633</td>\n",
       "      <td>5.181074e+07</td>\n",
       "      <td>1.274688e+06</td>\n",
       "      <td>1.879410e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9583.0</td>\n",
       "      <td>2.640550e+05</td>\n",
       "      <td>1.243699e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>u3090</td>\n",
       "      <td>0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>232.901849</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>153.145455</td>\n",
       "      <td>25269.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>43030.767176</td>\n",
       "      <td>2.254812e+07</td>\n",
       "      <td>4.481076e+06</td>\n",
       "      <td>7.590978e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>6.050700e+05</td>\n",
       "      <td>3.170567e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>u1450</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>508.886998</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>384.579487</td>\n",
       "      <td>74993.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8511.0</td>\n",
       "      <td>150824.232514</td>\n",
       "      <td>7.978602e+07</td>\n",
       "      <td>3.033095e+06</td>\n",
       "      <td>2.728573e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20094.0</td>\n",
       "      <td>7.982886e+05</td>\n",
       "      <td>4.222947e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>u3011</td>\n",
       "      <td>0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>259.821897</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>173.843602</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>4.720000e+02</td>\n",
       "      <td>3.302189e+02</td>\n",
       "      <td>5.420000e+02</td>\n",
       "      <td>75.0</td>\n",
       "      <td>308.5</td>\n",
       "      <td>3.085000e+02</td>\n",
       "      <td>6.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>u1157</td>\n",
       "      <td>0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>142.690855</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>107.543011</td>\n",
       "      <td>40006.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>5.360000e+02</td>\n",
       "      <td>3.634529e+02</td>\n",
       "      <td>5.660000e+02</td>\n",
       "      <td>52.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>6.180000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u4830</td>\n",
       "      <td>1</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>104.767253</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>67.341495</td>\n",
       "      <td>104514.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6963.0</td>\n",
       "      <td>123642.121745</td>\n",
       "      <td>1.756955e+08</td>\n",
       "      <td>7.580323e+06</td>\n",
       "      <td>2.033085e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15941.0</td>\n",
       "      <td>9.196338e+05</td>\n",
       "      <td>1.306800e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>u2212</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>221.421430</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>127.961538</td>\n",
       "      <td>6654.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5954.5</td>\n",
       "      <td>25485.690000</td>\n",
       "      <td>2.548569e+06</td>\n",
       "      <td>1.126448e+05</td>\n",
       "      <td>8.974380e+05</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5724.5</td>\n",
       "      <td>3.614053e+04</td>\n",
       "      <td>3.614053e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>u1141</td>\n",
       "      <td>0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>154.448336</td>\n",
       "      <td>930.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>109.568493</td>\n",
       "      <td>15997.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>111400.849549</td>\n",
       "      <td>1.110666e+08</td>\n",
       "      <td>5.241572e+06</td>\n",
       "      <td>8.999828e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7481.0</td>\n",
       "      <td>8.608799e+05</td>\n",
       "      <td>8.582973e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>u0954</td>\n",
       "      <td>0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>128.467158</td>\n",
       "      <td>942.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>86.706601</td>\n",
       "      <td>35463.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>2045.373134</td>\n",
       "      <td>1.370400e+05</td>\n",
       "      <td>3.273320e+04</td>\n",
       "      <td>2.488320e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>8.169134e+03</td>\n",
       "      <td>5.473320e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>u2702</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>166.325233</td>\n",
       "      <td>922.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>123.605263</td>\n",
       "      <td>4697.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20196.0</td>\n",
       "      <td>243574.266667</td>\n",
       "      <td>1.096084e+07</td>\n",
       "      <td>4.725283e+06</td>\n",
       "      <td>2.458034e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26625.0</td>\n",
       "      <td>1.606755e+06</td>\n",
       "      <td>7.230399e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>u3693</td>\n",
       "      <td>0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>167.943012</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>108.857143</td>\n",
       "      <td>46482.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>142609.083032</td>\n",
       "      <td>1.975136e+08</td>\n",
       "      <td>7.366432e+06</td>\n",
       "      <td>1.798444e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6981.0</td>\n",
       "      <td>1.133878e+06</td>\n",
       "      <td>1.570421e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>u1622</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>121.688406</td>\n",
       "      <td>595.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>7294.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5706.0</td>\n",
       "      <td>627449.624430</td>\n",
       "      <td>1.237958e+09</td>\n",
       "      <td>1.809650e+07</td>\n",
       "      <td>3.728184e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13158.0</td>\n",
       "      <td>3.076433e+06</td>\n",
       "      <td>6.069803e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>u4401</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52.836414</td>\n",
       "      <td>207.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>62.074074</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11372.0</td>\n",
       "      <td>131774.136024</td>\n",
       "      <td>3.884702e+08</td>\n",
       "      <td>3.269868e+06</td>\n",
       "      <td>8.092677e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18548.0</td>\n",
       "      <td>5.470142e+05</td>\n",
       "      <td>1.612598e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>u4302</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.839866</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7493.0</td>\n",
       "      <td>491395.548826</td>\n",
       "      <td>1.046673e+09</td>\n",
       "      <td>9.131289e+07</td>\n",
       "      <td>2.299773e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20469.5</td>\n",
       "      <td>1.497868e+07</td>\n",
       "      <td>3.190458e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>u1408</td>\n",
       "      <td>0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>243.132800</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>104.635838</td>\n",
       "      <td>18102.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2586.5</td>\n",
       "      <td>65661.003348</td>\n",
       "      <td>5.883226e+07</td>\n",
       "      <td>1.265095e+07</td>\n",
       "      <td>3.443119e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>1.047411e+06</td>\n",
       "      <td>9.384798e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>u4538</td>\n",
       "      <td>1</td>\n",
       "      <td>129.0</td>\n",
       "      <td>93.273576</td>\n",
       "      <td>729.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>73.906977</td>\n",
       "      <td>9534.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6453.0</td>\n",
       "      <td>365029.152174</td>\n",
       "      <td>1.158603e+09</td>\n",
       "      <td>2.593660e+07</td>\n",
       "      <td>1.261232e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14985.0</td>\n",
       "      <td>2.771398e+06</td>\n",
       "      <td>8.796418e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>u0478</td>\n",
       "      <td>0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>249.863852</td>\n",
       "      <td>2087.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>139.125000</td>\n",
       "      <td>45633.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>122.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>20935.548387</td>\n",
       "      <td>6.490020e+05</td>\n",
       "      <td>8.623396e+04</td>\n",
       "      <td>3.877720e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.986848e+04</td>\n",
       "      <td>9.259230e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>u3026</td>\n",
       "      <td>0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>37.755122</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.587421</td>\n",
       "      <td>33062.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3946.0</td>\n",
       "      <td>13047.272727</td>\n",
       "      <td>2.296320e+06</td>\n",
       "      <td>1.824292e+05</td>\n",
       "      <td>1.991571e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2418.0</td>\n",
       "      <td>4.498466e+04</td>\n",
       "      <td>7.917301e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>u3034</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>59.230904</td>\n",
       "      <td>182.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>99.5</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>639.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7710.0</td>\n",
       "      <td>265444.480000</td>\n",
       "      <td>3.318056e+07</td>\n",
       "      <td>1.721242e+08</td>\n",
       "      <td>1.858947e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20369.0</td>\n",
       "      <td>2.332003e+07</td>\n",
       "      <td>2.915003e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>u2821</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>9519.929340</td>\n",
       "      <td>91487.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>1245.434783</td>\n",
       "      <td>114580.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>132.5</td>\n",
       "      <td>451.500000</td>\n",
       "      <td>3.612000e+03</td>\n",
       "      <td>1.466444e+02</td>\n",
       "      <td>3.970000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.152000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>u4649</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102.288574</td>\n",
       "      <td>291.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>117.571429</td>\n",
       "      <td>823.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8223.0</td>\n",
       "      <td>446426.556373</td>\n",
       "      <td>1.092852e+09</td>\n",
       "      <td>4.569633e+07</td>\n",
       "      <td>1.158753e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15806.0</td>\n",
       "      <td>5.967695e+06</td>\n",
       "      <td>1.460892e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>u3421</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>169.375098</td>\n",
       "      <td>754.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>77.850000</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8060.5</td>\n",
       "      <td>108888.246667</td>\n",
       "      <td>2.776650e+08</td>\n",
       "      <td>4.110665e+06</td>\n",
       "      <td>1.511527e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12779.5</td>\n",
       "      <td>6.123098e+05</td>\n",
       "      <td>1.561390e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>u4118</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.867228</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4156.5</td>\n",
       "      <td>70396.300000</td>\n",
       "      <td>7.743593e+06</td>\n",
       "      <td>5.843205e+06</td>\n",
       "      <td>4.957483e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6471.0</td>\n",
       "      <td>1.195817e+06</td>\n",
       "      <td>1.315399e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>u4667</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>50.118288</td>\n",
       "      <td>304.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>55.569231</td>\n",
       "      <td>3612.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6594.0</td>\n",
       "      <td>427005.213169</td>\n",
       "      <td>5.188113e+08</td>\n",
       "      <td>8.961543e+07</td>\n",
       "      <td>1.328676e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8673.0</td>\n",
       "      <td>1.307901e+07</td>\n",
       "      <td>1.589099e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>u4180</td>\n",
       "      <td>1</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>88.270811</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>62.771626</td>\n",
       "      <td>126987.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4444.5</td>\n",
       "      <td>297522.266063</td>\n",
       "      <td>6.575242e+08</td>\n",
       "      <td>1.542719e+07</td>\n",
       "      <td>5.835209e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8425.0</td>\n",
       "      <td>1.649878e+06</td>\n",
       "      <td>3.646230e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>u1239</td>\n",
       "      <td>0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>280.994631</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>166.609929</td>\n",
       "      <td>23492.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7486.0</td>\n",
       "      <td>161708.098495</td>\n",
       "      <td>3.546259e+08</td>\n",
       "      <td>4.582015e+06</td>\n",
       "      <td>1.120371e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12291.0</td>\n",
       "      <td>7.171004e+05</td>\n",
       "      <td>1.572601e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>u2706</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>256.154924</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>135.480620</td>\n",
       "      <td>17477.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5361.0</td>\n",
       "      <td>177509.104036</td>\n",
       "      <td>4.794521e+08</td>\n",
       "      <td>1.257675e+07</td>\n",
       "      <td>4.117969e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8388.0</td>\n",
       "      <td>1.523673e+06</td>\n",
       "      <td>4.115440e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>u4694</td>\n",
       "      <td>1</td>\n",
       "      <td>270.0</td>\n",
       "      <td>352.753647</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>256.922222</td>\n",
       "      <td>69369.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9633.0</td>\n",
       "      <td>257221.638478</td>\n",
       "      <td>8.182220e+08</td>\n",
       "      <td>2.447857e+07</td>\n",
       "      <td>1.142567e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23484.0</td>\n",
       "      <td>2.640564e+06</td>\n",
       "      <td>8.399635e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>u3562</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>60.542620</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>54.935484</td>\n",
       "      <td>5109.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>69924.498681</td>\n",
       "      <td>2.650138e+07</td>\n",
       "      <td>9.073036e+06</td>\n",
       "      <td>1.170654e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2068.0</td>\n",
       "      <td>1.008153e+06</td>\n",
       "      <td>3.820900e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>u0609</td>\n",
       "      <td>0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>255.026206</td>\n",
       "      <td>2545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>116.558511</td>\n",
       "      <td>21913.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>470.5</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>1.884000e+03</td>\n",
       "      <td>2.318324e+02</td>\n",
       "      <td>6.380000e+02</td>\n",
       "      <td>146.0</td>\n",
       "      <td>293.5</td>\n",
       "      <td>3.427500e+02</td>\n",
       "      <td>1.371000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>u2479</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.778175</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5107.5</td>\n",
       "      <td>65577.156340</td>\n",
       "      <td>9.102109e+07</td>\n",
       "      <td>7.483612e+06</td>\n",
       "      <td>2.050473e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9568.5</td>\n",
       "      <td>7.864548e+05</td>\n",
       "      <td>1.091599e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>u3928</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.922402</td>\n",
       "      <td>260.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>33.977778</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8150.0</td>\n",
       "      <td>99216.620690</td>\n",
       "      <td>2.157962e+08</td>\n",
       "      <td>1.230552e+07</td>\n",
       "      <td>3.846599e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13960.0</td>\n",
       "      <td>1.029625e+06</td>\n",
       "      <td>2.239435e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>u0825</td>\n",
       "      <td>0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>103.930947</td>\n",
       "      <td>453.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.388889</td>\n",
       "      <td>5550.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>613.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>6.130000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.010000e+02</td>\n",
       "      <td>301.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>3.010000e+02</td>\n",
       "      <td>3.010000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>u3682</td>\n",
       "      <td>0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>412.002964</td>\n",
       "      <td>2909.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>223.343511</td>\n",
       "      <td>29258.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>19843.0</td>\n",
       "      <td>218168.479401</td>\n",
       "      <td>5.825098e+07</td>\n",
       "      <td>2.736178e+06</td>\n",
       "      <td>2.206839e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28022.0</td>\n",
       "      <td>7.840188e+05</td>\n",
       "      <td>2.093330e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>u4787</td>\n",
       "      <td>1</td>\n",
       "      <td>765.0</td>\n",
       "      <td>31.913990</td>\n",
       "      <td>621.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.350327</td>\n",
       "      <td>30868.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19656.0</td>\n",
       "      <td>297464.407080</td>\n",
       "      <td>3.361348e+07</td>\n",
       "      <td>2.941518e+07</td>\n",
       "      <td>2.865523e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15002.0</td>\n",
       "      <td>5.810488e+06</td>\n",
       "      <td>6.565851e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>u2399</td>\n",
       "      <td>0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>77.851174</td>\n",
       "      <td>457.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.907514</td>\n",
       "      <td>10537.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3057.0</td>\n",
       "      <td>133809.703400</td>\n",
       "      <td>1.141397e+08</td>\n",
       "      <td>5.733430e+06</td>\n",
       "      <td>1.175960e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6403.0</td>\n",
       "      <td>1.092231e+06</td>\n",
       "      <td>9.316731e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>u4935</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.453691</td>\n",
       "      <td>160.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>145.666667</td>\n",
       "      <td>8.740000e+02</td>\n",
       "      <td>2.538849e+03</td>\n",
       "      <td>6.356000e+03</td>\n",
       "      <td>80.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.174833e+03</td>\n",
       "      <td>7.049000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>u3111</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>179.531332</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>70.281250</td>\n",
       "      <td>2249.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>145017.057096</td>\n",
       "      <td>8.889546e+07</td>\n",
       "      <td>4.216437e+06</td>\n",
       "      <td>9.271999e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>4.085795e+05</td>\n",
       "      <td>2.504592e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>u2697</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.890873</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>50373.528329</td>\n",
       "      <td>3.556371e+07</td>\n",
       "      <td>3.428669e+06</td>\n",
       "      <td>4.917764e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1723.5</td>\n",
       "      <td>5.053274e+05</td>\n",
       "      <td>3.567611e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>u4958</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.648232</td>\n",
       "      <td>108.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>167.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>52924.860104</td>\n",
       "      <td>1.021450e+07</td>\n",
       "      <td>6.731377e+06</td>\n",
       "      <td>5.641375e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1.401760e+06</td>\n",
       "      <td>2.705396e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>u2989</td>\n",
       "      <td>0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>34.396087</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.177570</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>53187.097734</td>\n",
       "      <td>3.755009e+07</td>\n",
       "      <td>1.539297e+06</td>\n",
       "      <td>3.706898e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3969.0</td>\n",
       "      <td>2.056765e+05</td>\n",
       "      <td>1.452076e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>u1854</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>179.298237</td>\n",
       "      <td>518.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154.304348</td>\n",
       "      <td>3549.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>986.425532</td>\n",
       "      <td>4.636200e+04</td>\n",
       "      <td>9.917017e+02</td>\n",
       "      <td>5.199000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>8.537021e+02</td>\n",
       "      <td>4.012400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>u3496</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>251.004586</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>110.085714</td>\n",
       "      <td>15412.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3337.0</td>\n",
       "      <td>164282.755421</td>\n",
       "      <td>1.894180e+08</td>\n",
       "      <td>5.864845e+06</td>\n",
       "      <td>9.762326e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6751.0</td>\n",
       "      <td>8.729924e+05</td>\n",
       "      <td>1.006560e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>u2674</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>120.796304</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>45.229592</td>\n",
       "      <td>8865.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>105114.485597</td>\n",
       "      <td>5.108564e+07</td>\n",
       "      <td>8.684338e+06</td>\n",
       "      <td>1.431032e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4841.5</td>\n",
       "      <td>1.296338e+06</td>\n",
       "      <td>6.300200e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>u0974</td>\n",
       "      <td>0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>152.261646</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>56.065217</td>\n",
       "      <td>7737.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10045.0</td>\n",
       "      <td>574141.259297</td>\n",
       "      <td>1.698310e+09</td>\n",
       "      <td>6.233740e+07</td>\n",
       "      <td>2.220772e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15958.5</td>\n",
       "      <td>4.947154e+06</td>\n",
       "      <td>1.463368e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows  89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid  label  voice_talk_time_count  voice_talk_time_std  \\\n",
       "0     u1877      0                   13.0           471.857934   \n",
       "1     u1332      0                  116.0           124.877918   \n",
       "2     u2758      0                   83.0            35.422205   \n",
       "3     u4601      1                   15.0            92.632762   \n",
       "4     u0795      0                  775.0           151.221809   \n",
       "5     u1953      0                   15.0            65.222549   \n",
       "6     u1639      0                  159.0            54.262087   \n",
       "7     u3519      0                    1.0             0.000000   \n",
       "8     u0210      0                  309.0           187.812419   \n",
       "9     u1153      0                    4.0            63.887271   \n",
       "10    u3578      0                   27.0           128.915607   \n",
       "11    u0247      0                  687.0            73.500461   \n",
       "12    u0930      0                    2.0           186.676190   \n",
       "13    u0800      0                   53.0           196.110581   \n",
       "14    u3910      0                   78.0           155.363892   \n",
       "15    u0122      0                  561.0           234.223060   \n",
       "16    u3090      0                  165.0           232.901849   \n",
       "17    u1450      0                  195.0           508.886998   \n",
       "18    u3011      0                  211.0           259.821897   \n",
       "19    u1157      0                  372.0           142.690855   \n",
       "20    u4830      1                 1552.0           104.767253   \n",
       "21    u2212      0                   52.0           221.421430   \n",
       "22    u1141      0                  146.0           154.448336   \n",
       "23    u0954      0                  409.0           128.467158   \n",
       "24    u2702      0                   38.0           166.325233   \n",
       "25    u3693      0                  427.0           167.943012   \n",
       "26    u1622      0                   84.0           121.688406   \n",
       "27    u4401      1                   27.0            52.836414   \n",
       "28    u4302      1                    5.0            20.839866   \n",
       "29    u1408      0                  173.0           243.132800   \n",
       "...     ...    ...                    ...                  ...   \n",
       "4969  u4538      1                  129.0            93.273576   \n",
       "4970  u0478      0                  328.0           249.863852   \n",
       "4971  u3026      0                  795.0            37.755122   \n",
       "4972  u3034      0                    6.0            59.230904   \n",
       "4973  u2821      0                   92.0          9519.929340   \n",
       "4974  u4649      1                    7.0           102.288574   \n",
       "4975  u3421      0                   20.0           169.375098   \n",
       "4976  u4118      1                    6.0            13.867228   \n",
       "4977  u4667      1                   65.0            50.118288   \n",
       "4978  u4180      1                 2023.0            88.270811   \n",
       "4979  u1239      0                  141.0           280.994631   \n",
       "4980  u2706      0                  129.0           256.154924   \n",
       "4981  u4694      1                  270.0           352.753647   \n",
       "4982  u3562      0                   93.0            60.542620   \n",
       "4983  u0609      0                  188.0           255.026206   \n",
       "4984  u2479      0                    2.0             7.778175   \n",
       "4985  u3928      0                   45.0            44.922402   \n",
       "4986  u0825      0                  108.0           103.930947   \n",
       "4987  u3682      0                  131.0           412.002964   \n",
       "4988  u4787      1                  765.0            31.913990   \n",
       "4989  u2399      0                  173.0            77.851174   \n",
       "4990  u4935      1                    3.0            85.453691   \n",
       "4991  u3111      0                   32.0           179.531332   \n",
       "4992  u2697      0                    2.0            38.890873   \n",
       "4993  u4958      1                    2.0            34.648232   \n",
       "4994  u2989      0                  107.0            34.396087   \n",
       "4995  u1854      0                   23.0           179.298237   \n",
       "4996  u3496      0                  140.0           251.004586   \n",
       "4997  u2674      0                  196.0           120.796304   \n",
       "4998  u0974      0                  138.0           152.261646   \n",
       "\n",
       "      voice_talk_time_max  voice_talk_time_min  voice_talk_time_median  \\\n",
       "0                  1752.0                  9.0                    46.0   \n",
       "1                   784.0                  5.0                    54.0   \n",
       "2                   238.0                  1.0                    25.0   \n",
       "3                   376.0                  1.0                    42.0   \n",
       "4                  1069.0                  1.0                    74.0   \n",
       "5                   207.0                 14.0                    90.0   \n",
       "6                   398.0                  5.0                    40.0   \n",
       "7                     1.0                  1.0                     1.0   \n",
       "8                  1191.0                  1.0                    67.0   \n",
       "9                   141.0                 11.0                    14.5   \n",
       "10                  574.0                  7.0                    35.0   \n",
       "11                  937.0                  1.0                    41.0   \n",
       "12                  278.0                 14.0                   146.0   \n",
       "13                 1044.0                  2.0                    35.0   \n",
       "14                  919.0                  5.0                    38.5   \n",
       "15                 2159.0                  1.0                    29.0   \n",
       "16                 1634.0                  6.0                    64.0   \n",
       "17                 1800.0                  1.0                   191.0   \n",
       "18                 1490.0                  1.0                    64.0   \n",
       "19                 1515.0                  1.0                    60.0   \n",
       "20                 2040.0                  1.0                    41.0   \n",
       "21                 1317.0                  4.0                    50.5   \n",
       "22                  930.0                  1.0                    47.5   \n",
       "23                  942.0                  2.0                    42.0   \n",
       "24                  922.0                 10.0                    66.0   \n",
       "25                 1639.0                  1.0                    56.0   \n",
       "26                  595.0                  2.0                    45.5   \n",
       "27                  207.0                  3.0                    48.0   \n",
       "28                   63.0                  8.0                    33.0   \n",
       "29                 2138.0                  1.0                    36.0   \n",
       "...                   ...                  ...                     ...   \n",
       "4969                729.0                  4.0                    47.0   \n",
       "4970               2087.0                  1.0                    45.0   \n",
       "4971                303.0                  1.0                    30.0   \n",
       "4972                182.0                 43.0                    99.5   \n",
       "4973              91487.0                  5.0                    60.5   \n",
       "4974                291.0                 22.0                    64.0   \n",
       "4975                754.0                  6.0                    22.0   \n",
       "4976                 40.0                  9.0                    16.5   \n",
       "4977                304.0                  3.0                    41.0   \n",
       "4978               1398.0                  1.0                    41.0   \n",
       "4979               1800.0                  5.0                    52.0   \n",
       "4980               1991.0                  1.0                    58.0   \n",
       "4981               1992.0                  1.0                   105.0   \n",
       "4982                301.0                  1.0                    32.0   \n",
       "4983               2545.0                  1.0                    47.5   \n",
       "4984                 14.0                  3.0                     8.5   \n",
       "4985                260.0                  6.0                    22.0   \n",
       "4986                453.0                  2.0                    12.0   \n",
       "4987               2909.0                  7.0                    73.0   \n",
       "4988                621.0                  1.0                    39.0   \n",
       "4989                457.0                  1.0                    32.0   \n",
       "4990                160.0                 11.0                    13.0   \n",
       "4991               1030.0                  1.0                    29.5   \n",
       "4992                 71.0                 16.0                    43.5   \n",
       "4993                108.0                 59.0                    83.5   \n",
       "4994                189.0                  1.0                    27.0   \n",
       "4995                518.0                 19.0                    46.0   \n",
       "4996               1708.0                  1.0                    30.0   \n",
       "4997               1478.0                  5.0                    18.0   \n",
       "4998               1580.0                  2.0                    27.5   \n",
       "\n",
       "      voice_talk_time_mean  voice_talk_time_sum  voice_opp_num_unique_count  \\\n",
       "0               192.923077               2508.0                         5.0   \n",
       "1                97.465517              11306.0                        30.0   \n",
       "2                35.590361               2954.0                        17.0   \n",
       "3                70.600000               1059.0                         2.0   \n",
       "4               127.316129              98670.0                       322.0   \n",
       "5                95.533333               1433.0                         6.0   \n",
       "6                57.371069               9122.0                        19.0   \n",
       "7                 1.000000                  1.0                         1.0   \n",
       "8               140.423948              43391.0                        74.0   \n",
       "9                45.250000                181.0                         2.0   \n",
       "10               93.185185               2516.0                         5.0   \n",
       "11               61.573508              42301.0                       208.0   \n",
       "12              146.000000                292.0                         1.0   \n",
       "13               91.792453               4865.0                         9.0   \n",
       "14               89.217949               6959.0                        47.0   \n",
       "15               96.067736              53894.0                       111.0   \n",
       "16              153.145455              25269.0                        37.0   \n",
       "17              384.579487              74993.0                         4.0   \n",
       "18              173.843602              36681.0                        29.0   \n",
       "19              107.543011              40006.0                       106.0   \n",
       "20               67.341495             104514.0                       176.0   \n",
       "21              127.961538               6654.0                        21.0   \n",
       "22              109.568493              15997.0                        60.0   \n",
       "23               86.706601              35463.0                        54.0   \n",
       "24              123.605263               4697.0                        15.0   \n",
       "25              108.857143              46482.0                       113.0   \n",
       "26               86.833333               7294.0                        37.0   \n",
       "27               62.074074               1676.0                         3.0   \n",
       "28               34.600000                173.0                         3.0   \n",
       "29              104.635838              18102.0                        25.0   \n",
       "...                    ...                  ...                         ...   \n",
       "4969             73.906977               9534.0                        35.0   \n",
       "4970            139.125000              45633.0                        33.0   \n",
       "4971             41.587421              33062.0                       223.0   \n",
       "4972            106.500000                639.0                         6.0   \n",
       "4973           1245.434783             114580.0                        13.0   \n",
       "4974            117.571429                823.0                         6.0   \n",
       "4975             77.850000               1557.0                        15.0   \n",
       "4976             21.500000                129.0                         5.0   \n",
       "4977             55.569231               3612.0                        21.0   \n",
       "4978             62.771626             126987.0                       160.0   \n",
       "4979            166.609929              23492.0                        47.0   \n",
       "4980            135.480620              17477.0                        14.0   \n",
       "4981            256.922222              69369.0                        31.0   \n",
       "4982             54.935484               5109.0                        14.0   \n",
       "4983            116.558511              21913.0                        34.0   \n",
       "4984              8.500000                 17.0                         2.0   \n",
       "4985             33.977778               1529.0                        32.0   \n",
       "4986             51.388889               5550.0                        90.0   \n",
       "4987            223.343511              29258.0                        30.0   \n",
       "4988             40.350327              30868.0                       159.0   \n",
       "4989             60.907514              10537.0                        73.0   \n",
       "4990             61.333333                184.0                         1.0   \n",
       "4991             70.281250               2249.0                        10.0   \n",
       "4992             43.500000                 87.0                         1.0   \n",
       "4993             83.500000                167.0                         1.0   \n",
       "4994             38.177570               4085.0                        23.0   \n",
       "4995            154.304348               3549.0                         6.0   \n",
       "4996            110.085714              15412.0                        26.0   \n",
       "4997             45.229592               8865.0                        43.0   \n",
       "4998             56.065217               7737.0                        21.0   \n",
       "\n",
       "            ...         wa_up_flow_min  wa_up_flow_median  wa_up_flow_mean  \\\n",
       "0           ...                   41.0             8202.0     88103.394619   \n",
       "1           ...                    0.0             3371.0    428466.830087   \n",
       "2           ...                   41.0             2966.0     25311.213270   \n",
       "3           ...                   40.0             6283.0    326201.416667   \n",
       "4           ...                    0.0             2224.5     35094.644788   \n",
       "5           ...                   40.0             8266.5    154972.211679   \n",
       "6           ...                    0.0             7603.0    218984.805004   \n",
       "7           ...                  195.0             6585.0    195346.600000   \n",
       "8           ...                    0.0             5301.0     56508.643529   \n",
       "9           ...                   65.0             7376.5    298102.033333   \n",
       "10          ...                    NaN                NaN              NaN   \n",
       "11          ...                    0.0             8365.0    186211.083449   \n",
       "12          ...                    0.0            11064.5     48697.045652   \n",
       "13          ...                   40.0             6368.0     80359.508475   \n",
       "14          ...                    0.0            15618.0    624616.821692   \n",
       "15          ...                    0.0             7479.0    110001.562633   \n",
       "16          ...                    0.0             1700.5     43030.767176   \n",
       "17          ...                    0.0             8511.0    150824.232514   \n",
       "18          ...                  125.0              236.0       236.000000   \n",
       "19          ...                   61.0              268.0       268.000000   \n",
       "20          ...                    0.0             6963.0    123642.121745   \n",
       "21          ...                    0.0             5954.5     25485.690000   \n",
       "22          ...                    0.0             5340.0    111400.849549   \n",
       "23          ...                    0.0              417.0      2045.373134   \n",
       "24          ...                   55.0            20196.0    243574.266667   \n",
       "25          ...                    0.0             4600.0    142609.083032   \n",
       "26          ...                    0.0             5706.0    627449.624430   \n",
       "27          ...                    0.0            11372.0    131774.136024   \n",
       "28          ...                    0.0             7493.0    491395.548826   \n",
       "29          ...                    0.0             2586.5     65661.003348   \n",
       "...         ...                    ...                ...              ...   \n",
       "4969        ...                    0.0             6453.0    365029.152174   \n",
       "4970        ...                  122.0              927.0     20935.548387   \n",
       "4971        ...                   71.0             3946.0     13047.272727   \n",
       "4972        ...                    0.0             7710.0    265444.480000   \n",
       "4973        ...                   40.0              132.5       451.500000   \n",
       "4974        ...                    0.0             8223.0    446426.556373   \n",
       "4975        ...                    0.0             8060.5    108888.246667   \n",
       "4976        ...                    0.0             4156.5     70396.300000   \n",
       "4977        ...                    0.0             6594.0    427005.213169   \n",
       "4978        ...                    0.0             4444.5    297522.266063   \n",
       "4979        ...                    0.0             7486.0    161708.098495   \n",
       "4980        ...                    0.0             5361.0    177509.104036   \n",
       "4981        ...                    0.0             9633.0    257221.638478   \n",
       "4982        ...                    0.0             2085.0     69924.498681   \n",
       "4983        ...                   67.0              470.5       471.000000   \n",
       "4984        ...                    0.0             5107.5     65577.156340   \n",
       "4985        ...                    0.0             8150.0     99216.620690   \n",
       "4986        ...                  613.0              613.0       613.000000   \n",
       "4987        ...                   41.0            19843.0    218168.479401   \n",
       "4988        ...                    0.0            19656.0    297464.407080   \n",
       "4989        ...                    0.0             3057.0    133809.703400   \n",
       "4990        ...                   80.0               86.0       145.666667   \n",
       "4991        ...                    0.0             1624.0    145017.057096   \n",
       "4992        ...                    0.0             1864.0     50373.528329   \n",
       "4993        ...                    0.0             1177.0     52924.860104   \n",
       "4994        ...                    0.0             3110.0     53187.097734   \n",
       "4995        ...                   41.0              913.0       986.425532   \n",
       "4996        ...                    0.0             3337.0    164282.755421   \n",
       "4997        ...                    0.0             2258.0    105114.485597   \n",
       "4998        ...                    0.0            10045.0    574141.259297   \n",
       "\n",
       "      wa_up_flow_sum  wa_down_flow_std  wa_down_flow_max  wa_down_flow_min  \\\n",
       "0       3.929411e+07      7.238801e+06      1.141611e+08               0.0   \n",
       "1       6.379871e+08      4.804560e+06      1.388108e+08               0.0   \n",
       "2       5.340666e+06      3.427026e+05      4.498169e+06               0.0   \n",
       "3       1.096037e+08      1.027373e+07      1.329986e+08               0.0   \n",
       "4       1.817903e+07      8.740399e+05      1.561364e+07               0.0   \n",
       "5       8.492477e+07      2.235862e+07      3.975613e+08               0.0   \n",
       "6       2.976004e+08      1.257740e+07      2.485892e+08               0.0   \n",
       "7       2.930199e+06      1.030225e+07      3.994208e+07             111.0   \n",
       "8       7.815145e+07      2.293714e+06      5.452587e+07               0.0   \n",
       "9       1.788612e+07      8.089902e+06      4.456530e+07              80.0   \n",
       "10      0.000000e+00               NaN               NaN               NaN   \n",
       "11      2.677715e+08      3.541292e+06      5.048560e+07               0.0   \n",
       "12      2.240064e+07      1.659858e+06      2.565724e+07               0.0   \n",
       "13      1.896484e+07      7.178760e+05      8.251934e+06               0.0   \n",
       "14      1.779533e+09      4.532703e+07      1.319733e+09               0.0   \n",
       "15      5.181074e+07      1.274688e+06      1.879410e+07               0.0   \n",
       "16      2.254812e+07      4.481076e+06      7.590978e+07               0.0   \n",
       "17      7.978602e+07      3.033095e+06      2.728573e+07               0.0   \n",
       "18      4.720000e+02      3.302189e+02      5.420000e+02              75.0   \n",
       "19      5.360000e+02      3.634529e+02      5.660000e+02              52.0   \n",
       "20      1.756955e+08      7.580323e+06      2.033085e+08               0.0   \n",
       "21      2.548569e+06      1.126448e+05      8.974380e+05              52.0   \n",
       "22      1.110666e+08      5.241572e+06      8.999828e+07               0.0   \n",
       "23      1.370400e+05      3.273320e+04      2.488320e+05               0.0   \n",
       "24      1.096084e+07      4.725283e+06      2.458034e+07               0.0   \n",
       "25      1.975136e+08      7.366432e+06      1.798444e+08               0.0   \n",
       "26      1.237958e+09      1.809650e+07      3.728184e+08               0.0   \n",
       "27      3.884702e+08      3.269868e+06      8.092677e+07               0.0   \n",
       "28      1.046673e+09      9.131289e+07      2.299773e+09               0.0   \n",
       "29      5.883226e+07      1.265095e+07      3.443119e+08               0.0   \n",
       "...              ...               ...               ...               ...   \n",
       "4969    1.158603e+09      2.593660e+07      1.261232e+09               0.0   \n",
       "4970    6.490020e+05      8.623396e+04      3.877720e+05               0.0   \n",
       "4971    2.296320e+06      1.824292e+05      1.991571e+06               0.0   \n",
       "4972    3.318056e+07      1.721242e+08      1.858947e+09               0.0   \n",
       "4973    3.612000e+03      1.466444e+02      3.970000e+02               0.0   \n",
       "4974    1.092852e+09      4.569633e+07      1.158753e+09               0.0   \n",
       "4975    2.776650e+08      4.110665e+06      1.511527e+08               0.0   \n",
       "4976    7.743593e+06      5.843205e+06      4.957483e+07               0.0   \n",
       "4977    5.188113e+08      8.961543e+07      1.328676e+09               0.0   \n",
       "4978    6.575242e+08      1.542719e+07      5.835209e+08               0.0   \n",
       "4979    3.546259e+08      4.582015e+06      1.120371e+08               0.0   \n",
       "4980    4.794521e+08      1.257675e+07      4.117969e+08               0.0   \n",
       "4981    8.182220e+08      2.447857e+07      1.142567e+09               0.0   \n",
       "4982    2.650138e+07      9.073036e+06      1.170654e+08               0.0   \n",
       "4983    1.884000e+03      2.318324e+02      6.380000e+02             146.0   \n",
       "4984    9.102109e+07      7.483612e+06      2.050473e+08               0.0   \n",
       "4985    2.157962e+08      1.230552e+07      3.846599e+08               0.0   \n",
       "4986    6.130000e+02      0.000000e+00      3.010000e+02             301.0   \n",
       "4987    5.825098e+07      2.736178e+06      2.206839e+07               0.0   \n",
       "4988    3.361348e+07      2.941518e+07      2.865523e+08               0.0   \n",
       "4989    1.141397e+08      5.733430e+06      1.175960e+08               0.0   \n",
       "4990    8.740000e+02      2.538849e+03      6.356000e+03              80.0   \n",
       "4991    8.889546e+07      4.216437e+06      9.271999e+07               0.0   \n",
       "4992    3.556371e+07      3.428669e+06      4.917764e+07               0.0   \n",
       "4993    1.021450e+07      6.731377e+06      5.641375e+07               0.0   \n",
       "4994    3.755009e+07      1.539297e+06      3.706898e+07               0.0   \n",
       "4995    4.636200e+04      9.917017e+02      5.199000e+03               0.0   \n",
       "4996    1.894180e+08      5.864845e+06      9.762326e+07               0.0   \n",
       "4997    5.108564e+07      8.684338e+06      1.431032e+08               0.0   \n",
       "4998    1.698310e+09      6.233740e+07      2.220772e+09               0.0   \n",
       "\n",
       "      wa_down_flow_median  wa_down_flow_mean  wa_down_flow_sum  \n",
       "0                 15610.0       1.123536e+06      5.010969e+08  \n",
       "1                  5477.0       6.544100e+05      9.744165e+08  \n",
       "2                  5469.0       7.510883e+04      1.584796e+07  \n",
       "3                  8045.0       1.345599e+06      4.521212e+08  \n",
       "4                  2673.5       1.830555e+05      9.482274e+07  \n",
       "5                 13036.0       2.459291e+06      1.347691e+09  \n",
       "6                 14227.0       2.275916e+06      3.092970e+09  \n",
       "7                  8767.0       2.703492e+06      4.055238e+07  \n",
       "8                  8060.0       3.100945e+05      4.288607e+08  \n",
       "9                 10064.0       2.277784e+06      1.366671e+08  \n",
       "10                    NaN                NaN      0.000000e+00  \n",
       "11                12237.0       9.049267e+05      1.301285e+09  \n",
       "12                15220.5       2.055417e+05      9.454916e+07  \n",
       "13                 9491.0       1.804563e+05      4.258769e+07  \n",
       "14                37942.0       5.317942e+06      1.515082e+10  \n",
       "15                 9583.0       2.640550e+05      1.243699e+08  \n",
       "16                 1497.0       6.050700e+05      3.170567e+08  \n",
       "17                20094.0       7.982886e+05      4.222947e+08  \n",
       "18                  308.5       3.085000e+02      6.170000e+02  \n",
       "19                  309.0       3.090000e+02      6.180000e+02  \n",
       "20                15941.0       9.196338e+05      1.306800e+09  \n",
       "21                 5724.5       3.614053e+04      3.614053e+06  \n",
       "22                 7481.0       8.608799e+05      8.582973e+08  \n",
       "23                  460.0       8.169134e+03      5.473320e+05  \n",
       "24                26625.0       1.606755e+06      7.230399e+07  \n",
       "25                 6981.0       1.133878e+06      1.570421e+09  \n",
       "26                13158.0       3.076433e+06      6.069803e+09  \n",
       "27                18548.0       5.470142e+05      1.612598e+09  \n",
       "28                20469.5       1.497868e+07      3.190458e+10  \n",
       "29                 3359.0       1.047411e+06      9.384798e+08  \n",
       "...                   ...                ...               ...  \n",
       "4969              14985.0       2.771398e+06      8.796418e+09  \n",
       "4970                220.0       2.986848e+04      9.259230e+05  \n",
       "4971               2418.0       4.498466e+04      7.917301e+06  \n",
       "4972              20369.0       2.332003e+07      2.915003e+09  \n",
       "4973                 94.5       1.440000e+02      1.152000e+03  \n",
       "4974              15806.0       5.967695e+06      1.460892e+10  \n",
       "4975              12779.5       6.123098e+05      1.561390e+09  \n",
       "4976               6471.0       1.195817e+06      1.315399e+08  \n",
       "4977               8673.0       1.307901e+07      1.589099e+10  \n",
       "4978               8425.0       1.649878e+06      3.646230e+09  \n",
       "4979              12291.0       7.171004e+05      1.572601e+09  \n",
       "4980               8388.0       1.523673e+06      4.115440e+09  \n",
       "4981              23484.0       2.640564e+06      8.399635e+09  \n",
       "4982               2068.0       1.008153e+06      3.820900e+08  \n",
       "4983                293.5       3.427500e+02      1.371000e+03  \n",
       "4984               9568.5       7.864548e+05      1.091599e+09  \n",
       "4985              13960.0       1.029625e+06      2.239435e+09  \n",
       "4986                301.0       3.010000e+02      3.010000e+02  \n",
       "4987              28022.0       7.840188e+05      2.093330e+08  \n",
       "4988              15002.0       5.810488e+06      6.565851e+08  \n",
       "4989               6403.0       1.092231e+06      9.316731e+08  \n",
       "4990                131.0       1.174833e+03      7.049000e+03  \n",
       "4991               1900.0       4.085795e+05      2.504592e+08  \n",
       "4992               1723.5       5.053274e+05      3.567611e+08  \n",
       "4993               1034.0       1.401760e+06      2.705396e+08  \n",
       "4994               3969.0       2.056765e+05      1.452076e+08  \n",
       "4995                528.0       8.537021e+02      4.012400e+04  \n",
       "4996               6751.0       8.729924e+05      1.006560e+09  \n",
       "4997               4841.5       1.296338e+06      6.300200e+08  \n",
       "4998              15958.5       4.947154e+06      1.463368e+10  \n",
       "\n",
       "[4999 rows x 89 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMetric(preds,dtrain):\n",
    "    \n",
    "    label = dtrain.get_label()\n",
    "    \n",
    "    \n",
    "    pre = pd.DataFrame({'preds':preds,'label':label})\n",
    "    pre = pre.sort_values(by='preds',ascending=False)\n",
    "    \n",
    "    auc = metrics.roc_auc_score(pre.label,pre.preds)\n",
    "\n",
    "    pre.preds=pre.preds.map(lambda x: 1 if x>=0.5 else 0)\n",
    "\n",
    "    f1 = metrics.f1_score(pre.label,pre.preds)\n",
    "    \n",
    "    \n",
    "    res = 0.6*auc +0.4*f1\n",
    "    \n",
    "    return 'res',res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f57ba6844a8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "log_cols=[\"Classifier\", \"evalMetric\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "t = train.drop(['uid'], axis=1)\n",
    "t = t.values\n",
    "X = t[0::, 1::]\n",
    "Y = t[0::, 0]\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, Y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        #print (len(Y_test)==len(train_predictions))\n",
    "        acc = accuracy_score(Y_test, train_predictions)\n",
    "        f1 = metrics.f1_score(Y_test, train_predictions)\n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += 0.6*acc+0.4*f1\n",
    "        else:\n",
    "            acc_dict[name] = 0.6*acc+0.4*f1\n",
    "            \n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] = acc_dict[clf] / 10.0\n",
    "    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "plt.xlabel('evalMetric')\n",
    "plt.title('Classifier evalMetric')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=\"evalMetric\", y=\"Classifier\", data=log, color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 3000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "ntrain, ntest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "      <th>voice_talk_time_count</th>\n",
       "      <th>voice_talk_time_std</th>\n",
       "      <th>voice_talk_time_max</th>\n",
       "      <th>voice_talk_time_min</th>\n",
       "      <th>voice_talk_time_median</th>\n",
       "      <th>voice_talk_time_mean</th>\n",
       "      <th>voice_talk_time_sum</th>\n",
       "      <th>voice_opp_num_unique_count</th>\n",
       "      <th>...</th>\n",
       "      <th>wa_up_flow_min</th>\n",
       "      <th>wa_up_flow_median</th>\n",
       "      <th>wa_up_flow_mean</th>\n",
       "      <th>wa_up_flow_sum</th>\n",
       "      <th>wa_down_flow_std</th>\n",
       "      <th>wa_down_flow_max</th>\n",
       "      <th>wa_down_flow_min</th>\n",
       "      <th>wa_down_flow_median</th>\n",
       "      <th>wa_down_flow_mean</th>\n",
       "      <th>wa_down_flow_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1877</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>471.857934</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>192.923077</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>88103.394619</td>\n",
       "      <td>39294114.0</td>\n",
       "      <td>7.238801e+06</td>\n",
       "      <td>114161100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15610.0</td>\n",
       "      <td>1.123536e+06</td>\n",
       "      <td>501096907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u1332</td>\n",
       "      <td>0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>124.877918</td>\n",
       "      <td>784.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>97.465517</td>\n",
       "      <td>11306.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>428466.830087</td>\n",
       "      <td>637987110.0</td>\n",
       "      <td>4.804560e+06</td>\n",
       "      <td>138810758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5477.0</td>\n",
       "      <td>6.544100e+05</td>\n",
       "      <td>974416489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2758</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>35.422205</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.590361</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>25311.213270</td>\n",
       "      <td>5340666.0</td>\n",
       "      <td>3.427026e+05</td>\n",
       "      <td>4498169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5469.0</td>\n",
       "      <td>7.510883e+04</td>\n",
       "      <td>15847964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u4601</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>92.632762</td>\n",
       "      <td>376.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.600000</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6283.0</td>\n",
       "      <td>326201.416667</td>\n",
       "      <td>109603676.0</td>\n",
       "      <td>1.027373e+07</td>\n",
       "      <td>132998615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8045.0</td>\n",
       "      <td>1.345599e+06</td>\n",
       "      <td>452121184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0795</td>\n",
       "      <td>0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>151.221809</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>127.316129</td>\n",
       "      <td>98670.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2224.5</td>\n",
       "      <td>35094.644788</td>\n",
       "      <td>18179026.0</td>\n",
       "      <td>8.740399e+05</td>\n",
       "      <td>15613644.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2673.5</td>\n",
       "      <td>1.830555e+05</td>\n",
       "      <td>94822741.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  label  voice_talk_time_count  voice_talk_time_std  \\\n",
       "0  u1877      0                   13.0           471.857934   \n",
       "1  u1332      0                  116.0           124.877918   \n",
       "2  u2758      0                   83.0            35.422205   \n",
       "3  u4601      1                   15.0            92.632762   \n",
       "4  u0795      0                  775.0           151.221809   \n",
       "\n",
       "   voice_talk_time_max  voice_talk_time_min  voice_talk_time_median  \\\n",
       "0               1752.0                  9.0                    46.0   \n",
       "1                784.0                  5.0                    54.0   \n",
       "2                238.0                  1.0                    25.0   \n",
       "3                376.0                  1.0                    42.0   \n",
       "4               1069.0                  1.0                    74.0   \n",
       "\n",
       "   voice_talk_time_mean  voice_talk_time_sum  voice_opp_num_unique_count  \\\n",
       "0            192.923077               2508.0                         5.0   \n",
       "1             97.465517              11306.0                        30.0   \n",
       "2             35.590361               2954.0                        17.0   \n",
       "3             70.600000               1059.0                         2.0   \n",
       "4            127.316129              98670.0                       322.0   \n",
       "\n",
       "         ...         wa_up_flow_min  wa_up_flow_median  wa_up_flow_mean  \\\n",
       "0        ...                   41.0             8202.0     88103.394619   \n",
       "1        ...                    0.0             3371.0    428466.830087   \n",
       "2        ...                   41.0             2966.0     25311.213270   \n",
       "3        ...                   40.0             6283.0    326201.416667   \n",
       "4        ...                    0.0             2224.5     35094.644788   \n",
       "\n",
       "   wa_up_flow_sum  wa_down_flow_std  wa_down_flow_max  wa_down_flow_min  \\\n",
       "0      39294114.0      7.238801e+06       114161100.0               0.0   \n",
       "1     637987110.0      4.804560e+06       138810758.0               0.0   \n",
       "2       5340666.0      3.427026e+05         4498169.0               0.0   \n",
       "3     109603676.0      1.027373e+07       132998615.0               0.0   \n",
       "4      18179026.0      8.740399e+05        15613644.0               0.0   \n",
       "\n",
       "   wa_down_flow_median  wa_down_flow_mean  wa_down_flow_sum  \n",
       "0              15610.0       1.123536e+06       501096907.0  \n",
       "1               5477.0       6.544100e+05       974416489.0  \n",
       "2               5469.0       7.510883e+04        15847964.0  \n",
       "3               8045.0       1.345599e+06       452121184.0  \n",
       "4               2673.5       1.830555e+05        94822741.0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['uid', 'label'], axis=1).values\n",
    "y_train = train['label']\n",
    "x_test = test.drop('uid', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3999"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [n for n in range(0, 1000)]\n",
    "b = [n for n in range(2000,4999)]\n",
    "len(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.8269567391847962\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "1\n",
      "0.8307076769192298\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "2\n",
      "0.8264566141535384\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "3\n",
      "0.8304576144036009\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "4\n",
      "0.831\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=800, max_depth=7, min_samples_leaf=2,verbose=0, oob_score=True, bootstrap=True)\n",
    "et_train = np.zeros((ntrain,))\n",
    "et_test = np.zeros((ntest,))\n",
    "et_test_skf = np.zeros((5, ntest))\n",
    "\n",
    "#test = 0:1000\n",
    "train_index = [n for n in range(1000, 4999)]\n",
    "test_index = [n for n in range(0, 1000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "et.fit(x_tr, y_tr)\n",
    "et_train[test_index] = et.predict(x_te)\n",
    "et_test_skf[0, :] = et.predict(x_test)\n",
    "print(0)\n",
    "print(et.oob_score_)\n",
    "print(et_test_skf[0,:])\n",
    "\n",
    "#test = 1000:2000\n",
    "train_index = [n for n in range(0, 1000)] + [n for n in range(2000, 4999)]\n",
    "test_index = [n for n in range(1000, 2000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "et.fit(x_tr, y_tr)\n",
    "et_train[test_index] = et.predict(x_te)\n",
    "et_test_skf[1, :] = et.predict(x_test)\n",
    "print(1)\n",
    "print(et.oob_score_)\n",
    "print(et_test_skf[1,:])\n",
    "\n",
    "#test = 2000:3000\n",
    "train_index = [n for n in range(0, 2000)] + [n for n in range(3000, 4999)]\n",
    "test_index = [n for n in range(2000, 3000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "et.fit(x_tr, y_tr)\n",
    "et_train[test_index] = et.predict(x_te)\n",
    "et_test_skf[2, :] = et.predict(x_test)\n",
    "print(2)\n",
    "print(et.oob_score_)\n",
    "print(et_test_skf[2,:])\n",
    "\n",
    "#test = 3000:4000\n",
    "train_index = [n for n in range(0, 3000)] + [n for n in range(4000, 4999)]\n",
    "test_index = [n for n in range(3000, 4000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "et.fit(x_tr, y_tr)\n",
    "et_train[test_index] = et.predict(x_te)\n",
    "et_test_skf[3, :] = et.predict(x_test)\n",
    "print(3)\n",
    "print(et.oob_score_)\n",
    "print(et_test_skf[3,:])\n",
    "\n",
    "#test = 4000:4999\n",
    "train_index = [n for n in range(0, 4000)]\n",
    "test_index = [n for n in range(4000, 4999)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "et.fit(x_tr, y_tr)\n",
    "et_train[test_index] = et.predict(x_te)\n",
    "et_test_skf[4, :] = et.predict(x_test)\n",
    "\n",
    "print(4)\n",
    "print(et.oob_score_)\n",
    "print(et_test_skf[4,:])\n",
    "\n",
    "et_test[:] = et_test_skf.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.8449612403100775\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "1\n",
      "0.8467116779194799\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "2\n",
      "0.8442110527631908\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "3\n",
      "0.8457114278569643\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "4\n",
      "0.844\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=800, max_depth=8, min_samples_leaf=2,verbose=0, max_features='sqrt',oob_score=True, bootstrap=True)\n",
    "rf_train = np.zeros((ntrain,))\n",
    "rf_test = np.zeros((ntest,))\n",
    "rf_test_skf = np.zeros((5, ntest))\n",
    "\n",
    "#test = 0:1000\n",
    "train_index = [n for n in range(1000, 4999)]\n",
    "test_index = [n for n in range(0, 1000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "rf.fit(x_tr, y_tr)\n",
    "rf_train[test_index] = rf.predict(x_te)\n",
    "rf_test_skf[0, :] = rf.predict(x_test)\n",
    "print(0)\n",
    "print(rf.oob_score_)\n",
    "print(rf_test_skf[0,:])\n",
    "\n",
    "#test = 1000:2000\n",
    "train_index = [n for n in range(0, 1000)] + [n for n in range(2000, 4999)]\n",
    "test_index = [n for n in range(1000, 2000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "rf.fit(x_tr, y_tr)\n",
    "rf_train[test_index] = rf.predict(x_te)\n",
    "rf_test_skf[1, :] = rf.predict(x_test)\n",
    "print(1)\n",
    "print(rf.oob_score_)\n",
    "print(rf_test_skf[1,:])\n",
    "\n",
    "#test = 2000:3000\n",
    "train_index = [n for n in range(0, 2000)] + [n for n in range(3000, 4999)]\n",
    "test_index = [n for n in range(2000, 3000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "rf.fit(x_tr, y_tr)\n",
    "rf_train[test_index] = rf.predict(x_te)\n",
    "rf_test_skf[2, :] = rf.predict(x_test)\n",
    "print(2)\n",
    "print(rf.oob_score_)\n",
    "print(rf_test_skf[2,:])\n",
    "\n",
    "#test = 3000:4000\n",
    "train_index = [n for n in range(0, 3000)] + [n for n in range(4000, 4999)]\n",
    "test_index = [n for n in range(3000, 4000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "rf.fit(x_tr, y_tr)\n",
    "rf_train[test_index] = rf.predict(x_te)\n",
    "rf_test_skf[3, :] = rf.predict(x_test)\n",
    "print(3)\n",
    "print(rf.oob_score_)\n",
    "print(rf_test_skf[3,:])\n",
    "\n",
    "#test = 4000:4999\n",
    "train_index = [n for n in range(0, 4000)]\n",
    "test_index = [n for n in range(4000, 4999)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "rf.fit(x_tr, y_tr)\n",
    "rf_train[test_index] = rf.predict(x_te)\n",
    "rf_test_skf[4, :] = rf.predict(x_test)\n",
    "\n",
    "print(4)\n",
    "print(rf.oob_score_)\n",
    "print(rf_test_skf[4,:])\n",
    "\n",
    "rf_test[:] = rf_test_skf.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1. 1. 0. ... 1. 0. 0.]\n",
      "1\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "2\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "3\n",
      "[1. 1. 0. ... 1. 0. 0.]\n",
      "4\n",
      "[0. 1. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=800, learning_rate=0.5)\n",
    "ada_train = np.zeros((ntrain,))\n",
    "ada_test = np.zeros((ntest,))\n",
    "ada_test_skf = np.zeros((5, ntest))\n",
    "\n",
    "#test = 0:1000\n",
    "train_index = [n for n in range(1000, 4999)]\n",
    "test_index = [n for n in range(0, 1000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "ada.fit(x_tr, y_tr)\n",
    "ada_train[test_index] = ada.predict(x_te)\n",
    "ada_test_skf[0, :] = ada.predict(x_test)\n",
    "print(0)\n",
    "print(ada_test_skf[0,:])\n",
    "\n",
    "#test = 1000:2000\n",
    "train_index = [n for n in range(0, 1000)] + [n for n in range(2000, 4999)]\n",
    "test_index = [n for n in range(1000, 2000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "ada.fit(x_tr, y_tr)\n",
    "ada_train[test_index] = ada.predict(x_te)\n",
    "ada_test_skf[1, :] = ada.predict(x_test)\n",
    "print(1)\n",
    "print(ada_test_skf[1,:])\n",
    "\n",
    "#test = 2000:3000\n",
    "train_index = [n for n in range(0, 2000)] + [n for n in range(3000, 4999)]\n",
    "test_index = [n for n in range(2000, 3000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "ada.fit(x_tr, y_tr)\n",
    "ada_train[test_index] = ada.predict(x_te)\n",
    "ada_test_skf[2, :] = ada.predict(x_test)\n",
    "print(2)\n",
    "print(ada_test_skf[2,:])\n",
    "\n",
    "#test = 3000:4000\n",
    "train_index = [n for n in range(0, 3000)] + [n for n in range(4000, 4999)]\n",
    "test_index = [n for n in range(3000, 4000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "ada.fit(x_tr, y_tr)\n",
    "ada_train[test_index] = ada.predict(x_te)\n",
    "ada_test_skf[3, :] = ada.predict(x_test)\n",
    "print(3)\n",
    "print(ada_test_skf[3,:])\n",
    "\n",
    "#test = 4000:4999\n",
    "train_index = [n for n in range(0, 4000)]\n",
    "test_index = [n for n in range(4000, 4999)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "ada.fit(x_tr, y_tr)\n",
    "ada_train[test_index] = ada.predict(x_te)\n",
    "ada_test_skf[4, :] = ada.predict(x_test)\n",
    "\n",
    "print(4)\n",
    "print(ada_test_skf[4,:])\n",
    "\n",
    "ada_test[:] = ada_test_skf.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "1\n",
      "[1. 0. 0. ... 1. 0. 0.]\n",
      "2\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "3\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "4\n",
      "[1. 1. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=800, subsample=0.8, max_depth=8, min_samples_leaf=2, learning_rate=0.5)\n",
    "gb_train = np.zeros((ntrain,))\n",
    "gb_test = np.zeros((ntest,))\n",
    "gb_test_skf = np.zeros((5, ntest))\n",
    "\n",
    "#test = 0:1000\n",
    "train_index = [n for n in range(1000, 4999)]\n",
    "test_index = [n for n in range(0, 1000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "gb.fit(x_tr, y_tr)\n",
    "gb_train[test_index] = gb.predict(x_te)\n",
    "gb_test_skf[0, :] = gb.predict(x_test)\n",
    "print(0)\n",
    "print(gb_test_skf[0,:])\n",
    "\n",
    "#test = 1000:2000\n",
    "train_index = [n for n in range(0, 1000)] + [n for n in range(2000, 4999)]\n",
    "test_index = [n for n in range(1000, 2000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "gb.fit(x_tr, y_tr)\n",
    "gb_train[test_index] = gb.predict(x_te)\n",
    "gb_test_skf[1, :] = gb.predict(x_test)\n",
    "print(1)\n",
    "print(gb_test_skf[1,:])\n",
    "\n",
    "#test = 2000:3000\n",
    "train_index = [n for n in range(0, 2000)] + [n for n in range(3000, 4999)]\n",
    "test_index = [n for n in range(2000, 3000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "gb.fit(x_tr, y_tr)\n",
    "gb_train[test_index] = gb.predict(x_te)\n",
    "gb_test_skf[2, :] = gb.predict(x_test)\n",
    "print(2)\n",
    "print(gb_test_skf[2,:])\n",
    "\n",
    "#test = 3000:4000\n",
    "train_index = [n for n in range(0, 3000)] + [n for n in range(4000, 4999)]\n",
    "test_index = [n for n in range(3000, 4000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "gb.fit(x_tr, y_tr)\n",
    "gb_train[test_index] = gb.predict(x_te)\n",
    "gb_test_skf[3, :] = gb.predict(x_test)\n",
    "print(3)\n",
    "print(gb_test_skf[3,:])\n",
    "\n",
    "#test = 4000:4999\n",
    "train_index = [n for n in range(0, 4000)]\n",
    "test_index = [n for n in range(4000, 4999)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "gb.fit(x_tr, y_tr)\n",
    "gb_train[test_index] = gb.predict(x_te)\n",
    "gb_test_skf[4, :] = gb.predict(x_test)\n",
    "\n",
    "print(4)\n",
    "print(gb_test_skf[4,:])\n",
    "\n",
    "gb_test[:] = gb_test_skf.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "1\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "2\n",
      "[1. 0. 0. ... 1. 0. 0.]\n",
      "3\n",
      "[1. 0. 0. ... 0. 1. 0.]\n",
      "4\n",
      "[1. 0. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt_train = np.zeros((ntrain,))\n",
    "dt_test = np.zeros((ntest,))\n",
    "dt_test_skf = np.zeros((5, ntest))\n",
    "\n",
    "#test = 0:1000\n",
    "train_index = [n for n in range(1000, 4999)]\n",
    "test_index = [n for n in range(0, 1000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dt.fit(x_tr, y_tr)\n",
    "dt_train[test_index] = dt.predict(x_te)\n",
    "dt_test_skf[0, :] = dt.predict(x_test)\n",
    "print(0)\n",
    "print(dt_test_skf[0,:])\n",
    "\n",
    "#test = 1000:2000\n",
    "train_index = [n for n in range(0, 1000)] + [n for n in range(2000, 4999)]\n",
    "test_index = [n for n in range(1000, 2000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dt.fit(x_tr, y_tr)\n",
    "dt_train[test_index] = dt.predict(x_te)\n",
    "dt_test_skf[1, :] = dt.predict(x_test)\n",
    "print(1)\n",
    "print(dt_test_skf[1,:])\n",
    "\n",
    "#test = 2000:3000\n",
    "train_index = [n for n in range(0, 2000)] + [n for n in range(3000, 4999)]\n",
    "test_index = [n for n in range(2000, 3000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dt.fit(x_tr, y_tr)\n",
    "dt_train[test_index] = dt.predict(x_te)\n",
    "dt_test_skf[2, :] = dt.predict(x_test)\n",
    "print(2)\n",
    "print(dt_test_skf[2,:])\n",
    "\n",
    "#test = 3000:4000\n",
    "train_index = [n for n in range(0, 3000)] + [n for n in range(4000, 4999)]\n",
    "test_index = [n for n in range(3000, 4000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dt.fit(x_tr, y_tr)\n",
    "dt_train[test_index] = dt.predict(x_te)\n",
    "dt_test_skf[3, :] = dt.predict(x_test)\n",
    "print(3)\n",
    "print(dt_test_skf[3,:])\n",
    "\n",
    "#test = 4000:4999\n",
    "train_index = [n for n in range(0, 4000)]\n",
    "test_index = [n for n in range(4000, 4999)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dt.fit(x_tr, y_tr)\n",
    "dt_train[test_index] = dt.predict(x_te)\n",
    "dt_test_skf[4, :] = dt.predict(x_test)\n",
    "\n",
    "print(4)\n",
    "print(dt_test_skf[4,:])\n",
    "\n",
    "dt_test[:] = dt_test_skf.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "dtrain = lgb.Dataset(train.drop(['uid','label'],axis=1),label=train.label)\n",
    "dtest = lgb.Dataset(test.drop(['uid'],axis=1))\n",
    "lgb_params =  {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "#    'metric': ('multi_logloss', 'multi_error'),\n",
    "    #'metric_freq': 100,\n",
    "    'is_training_metric': False,\n",
    "    'min_data_in_leaf': 12,\n",
    "    'num_leaves': 64,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'verbosity':-1,\n",
    "#    'gpu_device_id':2,\n",
    "#    'device':'gpu'\n",
    "#    'lambda_l1': 0.001,\n",
    "#    'skip_drop': 0.95,\n",
    "#    'max_drop' : 10\n",
    "    #'lambda_l2': 0.005\n",
    "    #'num_threads': 18\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tcv_agg's res: 0.750638 + 0.00677503\n",
      "[10]\tcv_agg's res: 0.757897 + 0.0151375\n",
      "[15]\tcv_agg's res: 0.767358 + 0.012449\n",
      "[20]\tcv_agg's res: 0.767568 + 0.0085614\n",
      "[25]\tcv_agg's res: 0.767793 + 0.0094007\n",
      "[30]\tcv_agg's res: 0.767477 + 0.0123825\n",
      "[35]\tcv_agg's res: 0.769392 + 0.0128688\n",
      "[40]\tcv_agg's res: 0.770462 + 0.0134955\n",
      "[45]\tcv_agg's res: 0.77309 + 0.0117773\n",
      "[50]\tcv_agg's res: 0.774598 + 0.013458\n",
      "[55]\tcv_agg's res: 0.774784 + 0.00994553\n",
      "[60]\tcv_agg's res: 0.775567 + 0.0119369\n",
      "[65]\tcv_agg's res: 0.775278 + 0.0106429\n",
      "[70]\tcv_agg's res: 0.776576 + 0.0102963\n",
      "[75]\tcv_agg's res: 0.774962 + 0.0118199\n",
      "[80]\tcv_agg's res: 0.775684 + 0.0115456\n",
      "[85]\tcv_agg's res: 0.774398 + 0.0111522\n",
      "[90]\tcv_agg's res: 0.774459 + 0.0117687\n",
      "[95]\tcv_agg's res: 0.773252 + 0.010758\n",
      "[100]\tcv_agg's res: 0.772779 + 0.0141027\n",
      "[105]\tcv_agg's res: 0.772099 + 0.0111854\n",
      "[110]\tcv_agg's res: 0.773938 + 0.0124653\n",
      "[115]\tcv_agg's res: 0.775981 + 0.0144032\n",
      "[120]\tcv_agg's res: 0.774675 + 0.0161521\n",
      "[125]\tcv_agg's res: 0.774106 + 0.0145018\n",
      "[130]\tcv_agg's res: 0.774718 + 0.0148829\n",
      "[135]\tcv_agg's res: 0.77512 + 0.0145327\n",
      "[140]\tcv_agg's res: 0.775408 + 0.0150063\n",
      "[145]\tcv_agg's res: 0.776582 + 0.0142475\n",
      "[150]\tcv_agg's res: 0.776241 + 0.0144927\n",
      "[155]\tcv_agg's res: 0.775105 + 0.0140305\n",
      "[160]\tcv_agg's res: 0.773389 + 0.0143404\n",
      "[165]\tcv_agg's res: 0.772798 + 0.0143548\n",
      "[170]\tcv_agg's res: 0.77342 + 0.0135298\n",
      "[175]\tcv_agg's res: 0.773824 + 0.0155621\n",
      "[180]\tcv_agg's res: 0.773106 + 0.0130027\n",
      "[185]\tcv_agg's res: 0.773733 + 0.0118747\n",
      "[190]\tcv_agg's res: 0.774988 + 0.0117323\n",
      "[195]\tcv_agg's res: 0.775172 + 0.0122295\n",
      "[200]\tcv_agg's res: 0.777185 + 0.0111948\n",
      "[205]\tcv_agg's res: 0.773906 + 0.0106585\n",
      "[210]\tcv_agg's res: 0.773642 + 0.00967721\n",
      "[215]\tcv_agg's res: 0.77157 + 0.0103406\n",
      "[220]\tcv_agg's res: 0.770987 + 0.0114223\n",
      "[225]\tcv_agg's res: 0.773399 + 0.0114844\n",
      "[230]\tcv_agg's res: 0.773945 + 0.0125892\n",
      "[235]\tcv_agg's res: 0.772276 + 0.0123097\n",
      "[240]\tcv_agg's res: 0.773229 + 0.0131682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'res-mean': [0.7047050475532721,\n",
       "  0.7340134246699769,\n",
       "  0.7422409804965038,\n",
       "  0.7438014558969686,\n",
       "  0.7506382151338754,\n",
       "  0.7522206818311076,\n",
       "  0.7531483048676967,\n",
       "  0.7550658591545453,\n",
       "  0.7589640071506727,\n",
       "  0.7578971878462079,\n",
       "  0.7558347051963045,\n",
       "  0.759977565645106,\n",
       "  0.7608622592279222,\n",
       "  0.7675193744835278,\n",
       "  0.7673581040491365,\n",
       "  0.7630379395179294,\n",
       "  0.7664656086530227,\n",
       "  0.7669575316450513,\n",
       "  0.7672085642337171,\n",
       "  0.7675682029962321,\n",
       "  0.7680661152207001,\n",
       "  0.7668308873426573,\n",
       "  0.7651856342951113,\n",
       "  0.7672676678894753,\n",
       "  0.7677928315676134,\n",
       "  0.768060419309725,\n",
       "  0.7688381417045078,\n",
       "  0.7679601707826288,\n",
       "  0.7661101750705243,\n",
       "  0.7674772621251295,\n",
       "  0.766040550139989,\n",
       "  0.766867670699836,\n",
       "  0.7673868697434146,\n",
       "  0.7666627873934901,\n",
       "  0.7693918403664574,\n",
       "  0.7697429765366018,\n",
       "  0.7674305454346498,\n",
       "  0.7676284277015083,\n",
       "  0.7713331944932381,\n",
       "  0.7704624775648717,\n",
       "  0.7720776205000187,\n",
       "  0.7739035135172173,\n",
       "  0.7736080843626564,\n",
       "  0.7735987909041606,\n",
       "  0.7730897228347415,\n",
       "  0.7742991247809549,\n",
       "  0.7734120324873773,\n",
       "  0.7726807275341784,\n",
       "  0.7736338186380652,\n",
       "  0.7745975699692694,\n",
       "  0.7761756205485456,\n",
       "  0.7745084273487141,\n",
       "  0.7744808575582743,\n",
       "  0.7744057235179529,\n",
       "  0.7747839022622407,\n",
       "  0.7735081643768039,\n",
       "  0.775699261294246,\n",
       "  0.7756705710661641,\n",
       "  0.7752867311482015,\n",
       "  0.7755671257475028,\n",
       "  0.7732499688358913,\n",
       "  0.7769932439141122,\n",
       "  0.7769172530502223,\n",
       "  0.7748993738772182,\n",
       "  0.7752778241632835,\n",
       "  0.7753233467472259,\n",
       "  0.7729506839850836,\n",
       "  0.774043186046503,\n",
       "  0.7767368011091182,\n",
       "  0.776576173436081,\n",
       "  0.7751472547310634,\n",
       "  0.7737481570365965,\n",
       "  0.7759347385890233,\n",
       "  0.7736472904217083,\n",
       "  0.7749619216881684,\n",
       "  0.774929387351217,\n",
       "  0.775100845693113,\n",
       "  0.7755919656324739,\n",
       "  0.776592491091925,\n",
       "  0.775684401081012,\n",
       "  0.7760489224484766,\n",
       "  0.7741391133537734,\n",
       "  0.7736345831767185,\n",
       "  0.7744069814079627,\n",
       "  0.7743979183878826,\n",
       "  0.7750816106600014,\n",
       "  0.7742921524607344,\n",
       "  0.7752061761898715,\n",
       "  0.7746298869824857,\n",
       "  0.7744594573513481,\n",
       "  0.7737296598086029,\n",
       "  0.7746457937779335,\n",
       "  0.775995884057263,\n",
       "  0.774667476890107,\n",
       "  0.7732517180009776,\n",
       "  0.7727618725717593,\n",
       "  0.7732395236362111,\n",
       "  0.7740149884413968,\n",
       "  0.7733501665505017,\n",
       "  0.7727791566050003,\n",
       "  0.7733043942049385,\n",
       "  0.7734331289453094,\n",
       "  0.7734064921170214,\n",
       "  0.7737109061479487,\n",
       "  0.7720989910839108,\n",
       "  0.7713717797775512,\n",
       "  0.7718152028972748,\n",
       "  0.7735578688534387,\n",
       "  0.7739809348885919,\n",
       "  0.773938049725472,\n",
       "  0.7729810152330755,\n",
       "  0.774089252364823,\n",
       "  0.774908958273207,\n",
       "  0.7743549730775072,\n",
       "  0.7759809509488607,\n",
       "  0.7739167982004447,\n",
       "  0.7743928783416999,\n",
       "  0.7747052711386533,\n",
       "  0.7750574486233656,\n",
       "  0.7746750846708274,\n",
       "  0.7746734075552381,\n",
       "  0.7745047940472389,\n",
       "  0.7747395423987036,\n",
       "  0.7743676869637236,\n",
       "  0.7741064244891042,\n",
       "  0.7748705149746998,\n",
       "  0.7754809364544953,\n",
       "  0.7742325111672052,\n",
       "  0.7748609623417266,\n",
       "  0.7747178754337591,\n",
       "  0.7745609349277948,\n",
       "  0.7740504467230495,\n",
       "  0.7734356126566989,\n",
       "  0.7754881053000634,\n",
       "  0.7751201834571049,\n",
       "  0.7745882442949737,\n",
       "  0.7748846635489909,\n",
       "  0.7745601296973262,\n",
       "  0.7740353265714655,\n",
       "  0.7754080254566461,\n",
       "  0.7747388839460899,\n",
       "  0.7754582161682776,\n",
       "  0.7773427275926125],\n",
       " 'res-stdv': [0.009359220327079146,\n",
       "  0.008005429498664519,\n",
       "  0.010228379912587685,\n",
       "  0.007359890521679953,\n",
       "  0.006775027704164893,\n",
       "  0.01003900242681408,\n",
       "  0.010031856042516527,\n",
       "  0.014691405653545006,\n",
       "  0.01369064842294928,\n",
       "  0.01513752328785871,\n",
       "  0.010068254423291982,\n",
       "  0.014177427764800262,\n",
       "  0.01053116569519091,\n",
       "  0.012915497613786193,\n",
       "  0.012449023514081508,\n",
       "  0.011087077487054606,\n",
       "  0.01246785136531011,\n",
       "  0.012284605056677183,\n",
       "  0.013338232217349524,\n",
       "  0.008561398370857886,\n",
       "  0.011017104510847652,\n",
       "  0.01103771412810913,\n",
       "  0.010664590269494054,\n",
       "  0.011254305048180929,\n",
       "  0.009400700098444516,\n",
       "  0.010670737184372517,\n",
       "  0.010317794330965436,\n",
       "  0.010601025377388744,\n",
       "  0.012252577255744966,\n",
       "  0.012382458059155691,\n",
       "  0.012729120515877775,\n",
       "  0.013635084555194295,\n",
       "  0.014119619462812719,\n",
       "  0.015078605400645033,\n",
       "  0.012868816897580933,\n",
       "  0.013112019951018104,\n",
       "  0.013187170198407431,\n",
       "  0.011917421312238677,\n",
       "  0.013491195356767228,\n",
       "  0.013495471764913863,\n",
       "  0.013120464793823628,\n",
       "  0.013630280707168775,\n",
       "  0.013518357425616407,\n",
       "  0.011927881077735522,\n",
       "  0.011777343263820784,\n",
       "  0.012476852035150655,\n",
       "  0.013431825018965586,\n",
       "  0.012251284905119944,\n",
       "  0.012112596656598685,\n",
       "  0.013457988256117862,\n",
       "  0.012636583104496916,\n",
       "  0.013607965823492685,\n",
       "  0.011387952097397378,\n",
       "  0.012030142115115017,\n",
       "  0.009945528287008199,\n",
       "  0.01218671245603804,\n",
       "  0.013351800474051094,\n",
       "  0.012732126810145336,\n",
       "  0.013586248675810894,\n",
       "  0.011936894045789726,\n",
       "  0.01162278678254469,\n",
       "  0.012486323969346727,\n",
       "  0.012304815516628338,\n",
       "  0.011549965622712403,\n",
       "  0.010642859603827852,\n",
       "  0.013476830663746225,\n",
       "  0.011624162148285424,\n",
       "  0.012316856263645953,\n",
       "  0.012153035813518325,\n",
       "  0.010296284107866212,\n",
       "  0.00918507185788412,\n",
       "  0.009447734749428246,\n",
       "  0.011351003367772828,\n",
       "  0.011836325864199903,\n",
       "  0.011819922477597318,\n",
       "  0.011992764326041613,\n",
       "  0.011741524807084548,\n",
       "  0.010983298044753051,\n",
       "  0.011552525301285213,\n",
       "  0.011545597812333228,\n",
       "  0.010967536700126781,\n",
       "  0.01116875764805307,\n",
       "  0.0091447167016933,\n",
       "  0.011990347732049308,\n",
       "  0.01115218099487566,\n",
       "  0.009433264446205493,\n",
       "  0.012124081496683843,\n",
       "  0.011392628567452455,\n",
       "  0.011575281417371856,\n",
       "  0.011768719247037445,\n",
       "  0.012461204860936192,\n",
       "  0.011527889712434016,\n",
       "  0.013907185180976243,\n",
       "  0.013096015407220376,\n",
       "  0.010758018495165493,\n",
       "  0.012113123117458711,\n",
       "  0.013537684830371832,\n",
       "  0.012237643022750733,\n",
       "  0.013281050106049117,\n",
       "  0.01410270396786075,\n",
       "  0.012358129393162146,\n",
       "  0.013105501819834511,\n",
       "  0.013030790523110873,\n",
       "  0.012038384941041265,\n",
       "  0.011185384793924506,\n",
       "  0.01167271600968767,\n",
       "  0.013677355587106926,\n",
       "  0.012571130595260278,\n",
       "  0.013206548894708308,\n",
       "  0.012465277004202607,\n",
       "  0.012963741204605897,\n",
       "  0.012880960724807976,\n",
       "  0.014637314680138687,\n",
       "  0.014065665483953134,\n",
       "  0.014403179696613803,\n",
       "  0.014315881087140889,\n",
       "  0.014734398184376796,\n",
       "  0.01478095656474329,\n",
       "  0.015384169975469042,\n",
       "  0.016152115872403273,\n",
       "  0.016444428578237847,\n",
       "  0.016830093188205424,\n",
       "  0.01596982210134691,\n",
       "  0.014583459011610843,\n",
       "  0.014501822290417033,\n",
       "  0.014090765165105117,\n",
       "  0.015477403149000668,\n",
       "  0.014513201666272447,\n",
       "  0.01442183255209798,\n",
       "  0.014882859877521097,\n",
       "  0.015953747829192955,\n",
       "  0.014311716030256692,\n",
       "  0.014216634921876619,\n",
       "  0.014091154314822378,\n",
       "  0.014532736437339228,\n",
       "  0.014531675683034,\n",
       "  0.015505208795078884,\n",
       "  0.01477050273651653,\n",
       "  0.015869598971794612,\n",
       "  0.015006265366022415,\n",
       "  0.015577480572884682,\n",
       "  0.01349350286124443,\n",
       "  0.014726515915451968]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.cv(lgb_params,dtrain,feval=evalMetric,early_stopping_rounds=100,verbose_eval=5,num_boost_round=10000,nfold=3,metrics=['evalMetric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttraining's binary_logloss: 0.481938\ttraining's res: 0.892778\n",
      "[10]\ttraining's binary_logloss: 0.36252\ttraining's res: 0.918001\n",
      "[15]\ttraining's binary_logloss: 0.285445\ttraining's res: 0.933784\n",
      "[20]\ttraining's binary_logloss: 0.231344\ttraining's res: 0.948975\n",
      "[25]\ttraining's binary_logloss: 0.191692\ttraining's res: 0.959324\n",
      "[30]\ttraining's binary_logloss: 0.16067\ttraining's res: 0.966608\n",
      "[35]\ttraining's binary_logloss: 0.136695\ttraining's res: 0.975209\n",
      "[40]\ttraining's binary_logloss: 0.116922\ttraining's res: 0.98209\n",
      "[45]\ttraining's binary_logloss: 0.100762\ttraining's res: 0.989666\n",
      "[50]\ttraining's binary_logloss: 0.0876239\ttraining's res: 0.995237\n",
      "[55]\ttraining's binary_logloss: 0.0762543\ttraining's res: 0.99723\n",
      "[60]\ttraining's binary_logloss: 0.0670973\ttraining's res: 0.999449\n",
      "[65]\ttraining's binary_logloss: 0.0591582\ttraining's res: 0.999725\n",
      "[70]\ttraining's binary_logloss: 0.0522545\ttraining's res: 1\n",
      "[75]\ttraining's binary_logloss: 0.0463132\ttraining's res: 1\n",
      "[80]\ttraining's binary_logloss: 0.0410961\ttraining's res: 1\n",
      "[85]\ttraining's binary_logloss: 0.0365363\ttraining's res: 1\n",
      "[90]\ttraining's binary_logloss: 0.032484\ttraining's res: 1\n",
      "[95]\ttraining's binary_logloss: 0.0288336\ttraining's res: 1\n",
      "[100]\ttraining's binary_logloss: 0.0259006\ttraining's res: 1\n",
      "[105]\ttraining's binary_logloss: 0.0229992\ttraining's res: 1\n",
      "[110]\ttraining's binary_logloss: 0.0204347\ttraining's res: 1\n",
      "[115]\ttraining's binary_logloss: 0.0181357\ttraining's res: 1\n",
      "[120]\ttraining's binary_logloss: 0.0162155\ttraining's res: 1\n",
      "[125]\ttraining's binary_logloss: 0.0144051\ttraining's res: 1\n",
      "[130]\ttraining's binary_logloss: 0.01291\ttraining's res: 1\n",
      "[135]\ttraining's binary_logloss: 0.0115458\ttraining's res: 1\n",
      "[140]\ttraining's binary_logloss: 0.0102412\ttraining's res: 1\n",
      "[145]\ttraining's binary_logloss: 0.00916321\ttraining's res: 1\n",
      "[150]\ttraining's binary_logloss: 0.00816364\ttraining's res: 1\n",
      "[155]\ttraining's binary_logloss: 0.00731294\ttraining's res: 1\n",
      "[160]\ttraining's binary_logloss: 0.00655022\ttraining's res: 1\n",
      "[165]\ttraining's binary_logloss: 0.00585029\ttraining's res: 1\n",
      "[170]\ttraining's binary_logloss: 0.00519222\ttraining's res: 1\n",
      "[175]\ttraining's binary_logloss: 0.00461009\ttraining's res: 1\n",
      "[180]\ttraining's binary_logloss: 0.00413487\ttraining's res: 1\n",
      "[185]\ttraining's binary_logloss: 0.0036811\ttraining's res: 1\n",
      "[190]\ttraining's binary_logloss: 0.00329525\ttraining's res: 1\n",
      "[195]\ttraining's binary_logloss: 0.00294703\ttraining's res: 1\n",
      "[200]\ttraining's binary_logloss: 0.00264647\ttraining's res: 1\n",
      "[205]\ttraining's binary_logloss: 0.00238233\ttraining's res: 1\n",
      "[210]\ttraining's binary_logloss: 0.00212893\ttraining's res: 1\n",
      "[215]\ttraining's binary_logloss: 0.00189484\ttraining's res: 1\n",
      "[220]\ttraining's binary_logloss: 0.00169708\ttraining's res: 1\n",
      "[225]\ttraining's binary_logloss: 0.00151661\ttraining's res: 1\n",
      "[230]\ttraining's binary_logloss: 0.00135147\ttraining's res: 1\n",
      "[235]\ttraining's binary_logloss: 0.00120532\ttraining's res: 1\n",
      "[240]\ttraining's binary_logloss: 0.00107356\ttraining's res: 1\n",
      "[245]\ttraining's binary_logloss: 0.000959003\ttraining's res: 1\n",
      "[250]\ttraining's binary_logloss: 0.000862052\ttraining's res: 1\n",
      "[255]\ttraining's binary_logloss: 0.00077047\ttraining's res: 1\n",
      "[260]\ttraining's binary_logloss: 0.000686639\ttraining's res: 1\n",
      "[265]\ttraining's binary_logloss: 0.000613291\ttraining's res: 1\n",
      "[270]\ttraining's binary_logloss: 0.000546449\ttraining's res: 1\n",
      "[275]\ttraining's binary_logloss: 0.000485241\ttraining's res: 1\n",
      "[280]\ttraining's binary_logloss: 0.000433391\ttraining's res: 1\n",
      "[285]\ttraining's binary_logloss: 0.000387437\ttraining's res: 1\n",
      "[290]\ttraining's binary_logloss: 0.000345532\ttraining's res: 1\n",
      "[295]\ttraining's binary_logloss: 0.000307821\ttraining's res: 1\n",
      "[300]\ttraining's binary_logloss: 0.00027592\ttraining's res: 1\n",
      "0\n",
      "[9.36763174e-01 9.50743175e-01 4.22240034e-04 ... 2.03406172e-01\n",
      " 2.30060799e-04 4.18670960e-02]\n",
      "[5]\ttraining's binary_logloss: 0.485972\ttraining's res: 0.888856\n",
      "[10]\ttraining's binary_logloss: 0.361564\ttraining's res: 0.914739\n",
      "[15]\ttraining's binary_logloss: 0.282744\ttraining's res: 0.938419\n",
      "[20]\ttraining's binary_logloss: 0.229146\ttraining's res: 0.949366\n",
      "[25]\ttraining's binary_logloss: 0.188879\ttraining's res: 0.958739\n",
      "[30]\ttraining's binary_logloss: 0.157969\ttraining's res: 0.967064\n",
      "[35]\ttraining's binary_logloss: 0.134256\ttraining's res: 0.977125\n",
      "[40]\ttraining's binary_logloss: 0.11446\ttraining's res: 0.985014\n",
      "[45]\ttraining's binary_logloss: 0.0990415\ttraining's res: 0.990054\n",
      "[50]\ttraining's binary_logloss: 0.0857453\ttraining's res: 0.995681\n",
      "[55]\ttraining's binary_logloss: 0.0747819\ttraining's res: 0.997154\n",
      "[60]\ttraining's binary_logloss: 0.0658064\ttraining's res: 0.998297\n",
      "[65]\ttraining's binary_logloss: 0.0578615\ttraining's res: 0.999434\n",
      "[70]\ttraining's binary_logloss: 0.0510653\ttraining's res: 1\n",
      "[75]\ttraining's binary_logloss: 0.0450464\ttraining's res: 1\n",
      "[80]\ttraining's binary_logloss: 0.0399335\ttraining's res: 1\n",
      "[85]\ttraining's binary_logloss: 0.0354645\ttraining's res: 1\n",
      "[90]\ttraining's binary_logloss: 0.0316974\ttraining's res: 1\n",
      "[95]\ttraining's binary_logloss: 0.028127\ttraining's res: 1\n",
      "[100]\ttraining's binary_logloss: 0.0250892\ttraining's res: 1\n",
      "[105]\ttraining's binary_logloss: 0.0223092\ttraining's res: 1\n",
      "[110]\ttraining's binary_logloss: 0.0197676\ttraining's res: 1\n",
      "[115]\ttraining's binary_logloss: 0.0177344\ttraining's res: 1\n",
      "[120]\ttraining's binary_logloss: 0.015659\ttraining's res: 1\n",
      "[125]\ttraining's binary_logloss: 0.0139489\ttraining's res: 1\n",
      "[130]\ttraining's binary_logloss: 0.0124431\ttraining's res: 1\n",
      "[135]\ttraining's binary_logloss: 0.011041\ttraining's res: 1\n",
      "[140]\ttraining's binary_logloss: 0.00982171\ttraining's res: 1\n",
      "[145]\ttraining's binary_logloss: 0.0087896\ttraining's res: 1\n",
      "[150]\ttraining's binary_logloss: 0.00781525\ttraining's res: 1\n",
      "[155]\ttraining's binary_logloss: 0.00694863\ttraining's res: 1\n",
      "[160]\ttraining's binary_logloss: 0.00618715\ttraining's res: 1\n",
      "[165]\ttraining's binary_logloss: 0.0054957\ttraining's res: 1\n",
      "[170]\ttraining's binary_logloss: 0.0049208\ttraining's res: 1\n",
      "[175]\ttraining's binary_logloss: 0.00437285\ttraining's res: 1\n",
      "[180]\ttraining's binary_logloss: 0.00388802\ttraining's res: 1\n",
      "[185]\ttraining's binary_logloss: 0.00344698\ttraining's res: 1\n",
      "[190]\ttraining's binary_logloss: 0.00306623\ttraining's res: 1\n",
      "[195]\ttraining's binary_logloss: 0.00273659\ttraining's res: 1\n",
      "[200]\ttraining's binary_logloss: 0.00245197\ttraining's res: 1\n",
      "[205]\ttraining's binary_logloss: 0.00219774\ttraining's res: 1\n",
      "[210]\ttraining's binary_logloss: 0.00196164\ttraining's res: 1\n",
      "[215]\ttraining's binary_logloss: 0.00175215\ttraining's res: 1\n",
      "[220]\ttraining's binary_logloss: 0.00156646\ttraining's res: 1\n",
      "[225]\ttraining's binary_logloss: 0.00139893\ttraining's res: 1\n",
      "[230]\ttraining's binary_logloss: 0.00125275\ttraining's res: 1\n",
      "[235]\ttraining's binary_logloss: 0.00111196\ttraining's res: 1\n",
      "[240]\ttraining's binary_logloss: 0.000994473\ttraining's res: 1\n",
      "[245]\ttraining's binary_logloss: 0.000893957\ttraining's res: 1\n",
      "[250]\ttraining's binary_logloss: 0.000800581\ttraining's res: 1\n",
      "[255]\ttraining's binary_logloss: 0.000719112\ttraining's res: 1\n",
      "[260]\ttraining's binary_logloss: 0.000637104\ttraining's res: 1\n",
      "[265]\ttraining's binary_logloss: 0.000564089\ttraining's res: 1\n",
      "[270]\ttraining's binary_logloss: 0.000502693\ttraining's res: 1\n",
      "[275]\ttraining's binary_logloss: 0.000450795\ttraining's res: 1\n",
      "[280]\ttraining's binary_logloss: 0.000399866\ttraining's res: 1\n",
      "[285]\ttraining's binary_logloss: 0.000358751\ttraining's res: 1\n",
      "[290]\ttraining's binary_logloss: 0.000320197\ttraining's res: 1\n",
      "[295]\ttraining's binary_logloss: 0.00028723\ttraining's res: 1\n",
      "[300]\ttraining's binary_logloss: 0.000256996\ttraining's res: 1\n",
      "1\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[5]\ttraining's binary_logloss: 0.481561\ttraining's res: 0.901002\n",
      "[10]\ttraining's binary_logloss: 0.361736\ttraining's res: 0.921012\n",
      "[15]\ttraining's binary_logloss: 0.283757\ttraining's res: 0.936696\n",
      "[20]\ttraining's binary_logloss: 0.23224\ttraining's res: 0.949998\n",
      "[25]\ttraining's binary_logloss: 0.193428\ttraining's res: 0.960237\n",
      "[30]\ttraining's binary_logloss: 0.162692\ttraining's res: 0.96588\n",
      "[35]\ttraining's binary_logloss: 0.139035\ttraining's res: 0.976997\n",
      "[40]\ttraining's binary_logloss: 0.119874\ttraining's res: 0.984908\n",
      "[45]\ttraining's binary_logloss: 0.10357\ttraining's res: 0.990649\n",
      "[50]\ttraining's binary_logloss: 0.0901774\ttraining's res: 0.994733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\ttraining's binary_logloss: 0.0792019\ttraining's res: 0.997535\n",
      "[60]\ttraining's binary_logloss: 0.0695735\ttraining's res: 0.999183\n",
      "[65]\ttraining's binary_logloss: 0.0611848\ttraining's res: 0.999457\n",
      "[70]\ttraining's binary_logloss: 0.0541189\ttraining's res: 1\n",
      "[75]\ttraining's binary_logloss: 0.0478865\ttraining's res: 1\n",
      "[80]\ttraining's binary_logloss: 0.0423382\ttraining's res: 1\n",
      "[85]\ttraining's binary_logloss: 0.0377131\ttraining's res: 1\n",
      "[90]\ttraining's binary_logloss: 0.0337517\ttraining's res: 1\n",
      "[95]\ttraining's binary_logloss: 0.030227\ttraining's res: 1\n",
      "[100]\ttraining's binary_logloss: 0.026724\ttraining's res: 1\n",
      "[105]\ttraining's binary_logloss: 0.0237433\ttraining's res: 1\n",
      "[110]\ttraining's binary_logloss: 0.0210121\ttraining's res: 1\n",
      "[115]\ttraining's binary_logloss: 0.0187631\ttraining's res: 1\n",
      "[120]\ttraining's binary_logloss: 0.0166934\ttraining's res: 1\n",
      "[125]\ttraining's binary_logloss: 0.0149503\ttraining's res: 1\n",
      "[130]\ttraining's binary_logloss: 0.0132595\ttraining's res: 1\n",
      "[135]\ttraining's binary_logloss: 0.011853\ttraining's res: 1\n",
      "[140]\ttraining's binary_logloss: 0.0106668\ttraining's res: 1\n",
      "[145]\ttraining's binary_logloss: 0.00958541\ttraining's res: 1\n",
      "[150]\ttraining's binary_logloss: 0.00858693\ttraining's res: 1\n",
      "[155]\ttraining's binary_logloss: 0.00766644\ttraining's res: 1\n",
      "[160]\ttraining's binary_logloss: 0.00679221\ttraining's res: 1\n",
      "[165]\ttraining's binary_logloss: 0.00609185\ttraining's res: 1\n",
      "[170]\ttraining's binary_logloss: 0.0054172\ttraining's res: 1\n",
      "[175]\ttraining's binary_logloss: 0.00485114\ttraining's res: 1\n",
      "[180]\ttraining's binary_logloss: 0.00431329\ttraining's res: 1\n",
      "[185]\ttraining's binary_logloss: 0.00385593\ttraining's res: 1\n",
      "[190]\ttraining's binary_logloss: 0.00344336\ttraining's res: 1\n",
      "[195]\ttraining's binary_logloss: 0.00306382\ttraining's res: 1\n",
      "[200]\ttraining's binary_logloss: 0.00272742\ttraining's res: 1\n",
      "[205]\ttraining's binary_logloss: 0.00242892\ttraining's res: 1\n",
      "[210]\ttraining's binary_logloss: 0.00216532\ttraining's res: 1\n",
      "[215]\ttraining's binary_logloss: 0.00194331\ttraining's res: 1\n",
      "[220]\ttraining's binary_logloss: 0.00174019\ttraining's res: 1\n",
      "[225]\ttraining's binary_logloss: 0.00155454\ttraining's res: 1\n",
      "[230]\ttraining's binary_logloss: 0.00138901\ttraining's res: 1\n",
      "[235]\ttraining's binary_logloss: 0.00125301\ttraining's res: 1\n",
      "[240]\ttraining's binary_logloss: 0.00113153\ttraining's res: 1\n",
      "[245]\ttraining's binary_logloss: 0.00100549\ttraining's res: 1\n",
      "[250]\ttraining's binary_logloss: 0.000900331\ttraining's res: 1\n",
      "[255]\ttraining's binary_logloss: 0.000806184\ttraining's res: 1\n",
      "[260]\ttraining's binary_logloss: 0.000720543\ttraining's res: 1\n",
      "[265]\ttraining's binary_logloss: 0.000643553\ttraining's res: 1\n",
      "[270]\ttraining's binary_logloss: 0.000577683\ttraining's res: 1\n",
      "[275]\ttraining's binary_logloss: 0.000515545\ttraining's res: 1\n",
      "[280]\ttraining's binary_logloss: 0.000458191\ttraining's res: 1\n",
      "[285]\ttraining's binary_logloss: 0.00041239\ttraining's res: 1\n",
      "[290]\ttraining's binary_logloss: 0.00036764\ttraining's res: 1\n",
      "[295]\ttraining's binary_logloss: 0.000330107\ttraining's res: 1\n",
      "[300]\ttraining's binary_logloss: 0.000294464\ttraining's res: 1\n",
      "2\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[5]\ttraining's binary_logloss: 0.4807\ttraining's res: 0.901633\n",
      "[10]\ttraining's binary_logloss: 0.359594\ttraining's res: 0.919992\n",
      "[15]\ttraining's binary_logloss: 0.281966\ttraining's res: 0.933699\n",
      "[20]\ttraining's binary_logloss: 0.228137\ttraining's res: 0.945849\n",
      "[25]\ttraining's binary_logloss: 0.188638\ttraining's res: 0.959976\n",
      "[30]\ttraining's binary_logloss: 0.158436\ttraining's res: 0.969666\n",
      "[35]\ttraining's binary_logloss: 0.134842\ttraining's res: 0.977885\n",
      "[40]\ttraining's binary_logloss: 0.115334\ttraining's res: 0.983637\n",
      "[45]\ttraining's binary_logloss: 0.099438\ttraining's res: 0.988685\n",
      "[50]\ttraining's binary_logloss: 0.0869343\ttraining's res: 0.992851\n",
      "[55]\ttraining's binary_logloss: 0.075665\ttraining's res: 0.998028\n",
      "[60]\ttraining's binary_logloss: 0.0664946\ttraining's res: 0.998595\n",
      "[65]\ttraining's binary_logloss: 0.0586823\ttraining's res: 1\n",
      "[70]\ttraining's binary_logloss: 0.0518395\ttraining's res: 1\n",
      "[75]\ttraining's binary_logloss: 0.0461134\ttraining's res: 1\n",
      "[80]\ttraining's binary_logloss: 0.0411391\ttraining's res: 1\n",
      "[85]\ttraining's binary_logloss: 0.0364936\ttraining's res: 1\n",
      "[90]\ttraining's binary_logloss: 0.0324158\ttraining's res: 1\n",
      "[95]\ttraining's binary_logloss: 0.0289226\ttraining's res: 1\n",
      "[100]\ttraining's binary_logloss: 0.0258439\ttraining's res: 1\n",
      "[105]\ttraining's binary_logloss: 0.0231513\ttraining's res: 1\n",
      "[110]\ttraining's binary_logloss: 0.0205917\ttraining's res: 1\n",
      "[115]\ttraining's binary_logloss: 0.0183407\ttraining's res: 1\n",
      "[120]\ttraining's binary_logloss: 0.0163843\ttraining's res: 1\n",
      "[125]\ttraining's binary_logloss: 0.0146246\ttraining's res: 1\n",
      "[130]\ttraining's binary_logloss: 0.012942\ttraining's res: 1\n",
      "[135]\ttraining's binary_logloss: 0.0116018\ttraining's res: 1\n",
      "[140]\ttraining's binary_logloss: 0.0102722\ttraining's res: 1\n",
      "[145]\ttraining's binary_logloss: 0.00911544\ttraining's res: 1\n",
      "[150]\ttraining's binary_logloss: 0.00815449\ttraining's res: 1\n",
      "[155]\ttraining's binary_logloss: 0.00728347\ttraining's res: 1\n",
      "[160]\ttraining's binary_logloss: 0.00652287\ttraining's res: 1\n",
      "[165]\ttraining's binary_logloss: 0.00587303\ttraining's res: 1\n",
      "[170]\ttraining's binary_logloss: 0.00524287\ttraining's res: 1\n",
      "[175]\ttraining's binary_logloss: 0.00467377\ttraining's res: 1\n",
      "[180]\ttraining's binary_logloss: 0.0042046\ttraining's res: 1\n",
      "[185]\ttraining's binary_logloss: 0.00375286\ttraining's res: 1\n",
      "[190]\ttraining's binary_logloss: 0.00334136\ttraining's res: 1\n",
      "[195]\ttraining's binary_logloss: 0.00298313\ttraining's res: 1\n",
      "[200]\ttraining's binary_logloss: 0.00265843\ttraining's res: 1\n",
      "[205]\ttraining's binary_logloss: 0.00237371\ttraining's res: 1\n",
      "[210]\ttraining's binary_logloss: 0.00211398\ttraining's res: 1\n",
      "[215]\ttraining's binary_logloss: 0.00189696\ttraining's res: 1\n",
      "[220]\ttraining's binary_logloss: 0.00169973\ttraining's res: 1\n",
      "[225]\ttraining's binary_logloss: 0.00150592\ttraining's res: 1\n",
      "[230]\ttraining's binary_logloss: 0.00134257\ttraining's res: 1\n",
      "[235]\ttraining's binary_logloss: 0.00120278\ttraining's res: 1\n",
      "[240]\ttraining's binary_logloss: 0.00107815\ttraining's res: 1\n",
      "[245]\ttraining's binary_logloss: 0.000957933\ttraining's res: 1\n",
      "[250]\ttraining's binary_logloss: 0.000867047\ttraining's res: 1\n",
      "[255]\ttraining's binary_logloss: 0.00077784\ttraining's res: 1\n",
      "[260]\ttraining's binary_logloss: 0.000693509\ttraining's res: 1\n",
      "[265]\ttraining's binary_logloss: 0.000620067\ttraining's res: 1\n",
      "[270]\ttraining's binary_logloss: 0.000548044\ttraining's res: 1\n",
      "[275]\ttraining's binary_logloss: 0.000489422\ttraining's res: 1\n",
      "[280]\ttraining's binary_logloss: 0.00043809\ttraining's res: 1\n",
      "[285]\ttraining's binary_logloss: 0.000392802\ttraining's res: 1\n",
      "[290]\ttraining's binary_logloss: 0.000351278\ttraining's res: 1\n",
      "[295]\ttraining's binary_logloss: 0.000314603\ttraining's res: 1\n",
      "[300]\ttraining's binary_logloss: 0.000281665\ttraining's res: 1\n",
      "3\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[5]\ttraining's binary_logloss: 0.481634\ttraining's res: 0.897558\n",
      "[10]\ttraining's binary_logloss: 0.360162\ttraining's res: 0.923102\n",
      "[15]\ttraining's binary_logloss: 0.283872\ttraining's res: 0.934496\n",
      "[20]\ttraining's binary_logloss: 0.230114\ttraining's res: 0.951106\n",
      "[25]\ttraining's binary_logloss: 0.190447\ttraining's res: 0.963002\n",
      "[30]\ttraining's binary_logloss: 0.160285\ttraining's res: 0.972524\n",
      "[35]\ttraining's binary_logloss: 0.13639\ttraining's res: 0.978753\n",
      "[40]\ttraining's binary_logloss: 0.116545\ttraining's res: 0.985433\n",
      "[45]\ttraining's binary_logloss: 0.100743\ttraining's res: 0.98952\n",
      "[50]\ttraining's binary_logloss: 0.0873047\ttraining's res: 0.99399\n",
      "[55]\ttraining's binary_logloss: 0.0762621\ttraining's res: 0.997164\n",
      "[60]\ttraining's binary_logloss: 0.0669704\ttraining's res: 0.998591\n",
      "[65]\ttraining's binary_logloss: 0.0592909\ttraining's res: 0.999438\n",
      "[70]\ttraining's binary_logloss: 0.0525545\ttraining's res: 0.99972\n",
      "[75]\ttraining's binary_logloss: 0.0463478\ttraining's res: 1\n",
      "[80]\ttraining's binary_logloss: 0.0410023\ttraining's res: 1\n",
      "[85]\ttraining's binary_logloss: 0.0359798\ttraining's res: 1\n",
      "[90]\ttraining's binary_logloss: 0.0319917\ttraining's res: 1\n",
      "[95]\ttraining's binary_logloss: 0.0285387\ttraining's res: 1\n",
      "[100]\ttraining's binary_logloss: 0.0253836\ttraining's res: 1\n",
      "[105]\ttraining's binary_logloss: 0.0226328\ttraining's res: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110]\ttraining's binary_logloss: 0.0203078\ttraining's res: 1\n",
      "[115]\ttraining's binary_logloss: 0.0182138\ttraining's res: 1\n",
      "[120]\ttraining's binary_logloss: 0.0162388\ttraining's res: 1\n",
      "[125]\ttraining's binary_logloss: 0.0144739\ttraining's res: 1\n",
      "[130]\ttraining's binary_logloss: 0.0129004\ttraining's res: 1\n",
      "[135]\ttraining's binary_logloss: 0.011498\ttraining's res: 1\n",
      "[140]\ttraining's binary_logloss: 0.0102609\ttraining's res: 1\n",
      "[145]\ttraining's binary_logloss: 0.00918022\ttraining's res: 1\n",
      "[150]\ttraining's binary_logloss: 0.00820224\ttraining's res: 1\n",
      "[155]\ttraining's binary_logloss: 0.00734336\ttraining's res: 1\n",
      "[160]\ttraining's binary_logloss: 0.00652993\ttraining's res: 1\n",
      "[165]\ttraining's binary_logloss: 0.00581374\ttraining's res: 1\n",
      "[170]\ttraining's binary_logloss: 0.0051882\ttraining's res: 1\n",
      "[175]\ttraining's binary_logloss: 0.00462344\ttraining's res: 1\n",
      "[180]\ttraining's binary_logloss: 0.00410386\ttraining's res: 1\n",
      "[185]\ttraining's binary_logloss: 0.00367022\ttraining's res: 1\n",
      "[190]\ttraining's binary_logloss: 0.00327782\ttraining's res: 1\n",
      "[195]\ttraining's binary_logloss: 0.00292456\ttraining's res: 1\n",
      "[200]\ttraining's binary_logloss: 0.00261371\ttraining's res: 1\n",
      "[205]\ttraining's binary_logloss: 0.00231793\ttraining's res: 1\n",
      "[210]\ttraining's binary_logloss: 0.00206719\ttraining's res: 1\n",
      "[215]\ttraining's binary_logloss: 0.00184648\ttraining's res: 1\n",
      "[220]\ttraining's binary_logloss: 0.0016445\ttraining's res: 1\n",
      "[225]\ttraining's binary_logloss: 0.00146937\ttraining's res: 1\n",
      "[230]\ttraining's binary_logloss: 0.00131631\ttraining's res: 1\n",
      "[235]\ttraining's binary_logloss: 0.00118017\ttraining's res: 1\n",
      "[240]\ttraining's binary_logloss: 0.00105879\ttraining's res: 1\n",
      "[245]\ttraining's binary_logloss: 0.000944098\ttraining's res: 1\n",
      "[250]\ttraining's binary_logloss: 0.000842968\ttraining's res: 1\n",
      "[255]\ttraining's binary_logloss: 0.000750591\ttraining's res: 1\n",
      "[260]\ttraining's binary_logloss: 0.000667961\ttraining's res: 1\n",
      "[265]\ttraining's binary_logloss: 0.000596761\ttraining's res: 1\n",
      "[270]\ttraining's binary_logloss: 0.000535456\ttraining's res: 1\n",
      "[275]\ttraining's binary_logloss: 0.000478869\ttraining's res: 1\n",
      "[280]\ttraining's binary_logloss: 0.000429039\ttraining's res: 1\n",
      "[285]\ttraining's binary_logloss: 0.000384331\ttraining's res: 1\n",
      "[290]\ttraining's binary_logloss: 0.000344463\ttraining's res: 1\n",
      "[295]\ttraining's binary_logloss: 0.000306404\ttraining's res: 1\n",
      "[300]\ttraining's binary_logloss: 0.000274537\ttraining's res: 1\n",
      "4\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "lgb_train = np.zeros((ntrain,))\n",
    "lgb_test = np.zeros((ntest,))\n",
    "lgb_test_skf = np.zeros((5, ntest))\n",
    "\n",
    "#test = 0:1000\n",
    "train_index = [n for n in range(1000, 4999)]\n",
    "test_index = [n for n in range(0, 1000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dtrain = lgb.Dataset(x_tr,label=y_tr)\n",
    "model =lgb.train(lgb_params,dtrain,feval=evalMetric,verbose_eval=5,num_boost_round=300,valid_sets=[dtrain])\n",
    "lgb_train[test_index] = model.predict(x_te)\n",
    "lgb_test_skf[0, :] = model.predict(x_test)\n",
    "print(0)\n",
    "print(lgb_test_skf[0,:])\n",
    "\n",
    "#test = 1000:2000\n",
    "train_index = [n for n in range(0, 1000)] + [n for n in range(2000, 4999)]\n",
    "test_index = [n for n in range(1000, 2000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dtrain = lgb.Dataset(x_tr,label=y_tr)\n",
    "model =lgb.train(lgb_params,dtrain,feval=evalMetric,verbose_eval=5,num_boost_round=300,valid_sets=[dtrain])\n",
    "lgb_train[test_index] = model.predict(x_te)\n",
    "lgb_test_skf[0, :] = model.predict(x_test)\n",
    "print(1)\n",
    "print(lgb_test_skf[1,:])\n",
    "\n",
    "#test = 2000:3000\n",
    "train_index = [n for n in range(0, 2000)] + [n for n in range(3000, 4999)]\n",
    "test_index = [n for n in range(2000, 3000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dtrain = lgb.Dataset(x_tr,label=y_tr)\n",
    "model =lgb.train(lgb_params,dtrain,feval=evalMetric,verbose_eval=5,num_boost_round=300,valid_sets=[dtrain])\n",
    "lgb_train[test_index] = model.predict(x_te)\n",
    "lgb_test_skf[0, :] = model.predict(x_test)\n",
    "print(2)\n",
    "print(lgb_test_skf[2,:])\n",
    "\n",
    "#test = 3000:4000\n",
    "train_index = [n for n in range(0, 3000)] + [n for n in range(4000, 4999)]\n",
    "test_index = [n for n in range(3000, 4000)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dtrain = lgb.Dataset(x_tr,label=y_tr)\n",
    "model =lgb.train(lgb_params,dtrain,feval=evalMetric,verbose_eval=5,num_boost_round=300,valid_sets=[dtrain])\n",
    "lgb_train[test_index] = model.predict(x_te)\n",
    "lgb_test_skf[0, :] = model.predict(x_test)\n",
    "print(3)\n",
    "print(lgb_test_skf[3,:])\n",
    "\n",
    "#test = 4000:4999\n",
    "train_index = [n for n in range(0, 4000)]\n",
    "test_index = [n for n in range(4000, 4999)]\n",
    "x_tr = x_train[train_index]\n",
    "y_tr = y_train[train_index]\n",
    "x_te = x_train[test_index]\n",
    "\n",
    "dtrain = lgb.Dataset(x_tr,label=y_tr)\n",
    "model =lgb.train(lgb_params,dtrain,feval=evalMetric,verbose_eval=5,num_boost_round=300,valid_sets=[dtrain])\n",
    "lgb_train[test_index] = model.predict(x_te)\n",
    "lgb_test_skf[0, :] = model.predict(x_test)\n",
    "print(4)\n",
    "print(lgb_test_skf[4,:])\n",
    "\n",
    "lgb_test[:] = lgb_test_skf.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et</th>\n",
       "      <th>rf</th>\n",
       "      <th>ada</th>\n",
       "      <th>gb</th>\n",
       "      <th>dt</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.444298e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.643740e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.196706e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.947531e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.685404e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    et   rf  ada   gb   dt           lgb\n",
       "0  0.0  0.0  0.0  0.0  1.0  4.444298e-02\n",
       "1  0.0  0.0  0.0  0.0  0.0  3.643740e-04\n",
       "2  0.0  0.0  0.0  1.0  0.0  6.196706e-04\n",
       "3  0.0  0.0  1.0  0.0  1.0  9.947531e-01\n",
       "4  0.0  0.0  0.0  0.0  0.0  2.685404e-07"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_2 = pd.DataFrame()\n",
    "train_2['et'] = et_train\n",
    "train_2['rf'] = rf_train\n",
    "train_2['ada'] = ada_train\n",
    "train_2['gb'] = gb_train\n",
    "train_2['dt'] = dt_train\n",
    "train_2['lgb'] = lgb_train\n",
    "train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "xgb_params = {\n",
    "    'n_estimators':800,\n",
    "    'booster':'gbtree',\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':3,\n",
    "    'gamma':0.1,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.8,\n",
    "    'lambda':1,\n",
    "    'eta':0.05,\n",
    "    'seed':2000,\n",
    "    'silent':0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.131076+0.00109465\ttrain-res:0.779246+0.0111876\ttest-error:0.134427+0.00520339\ttest-res:0.773977+0.00409783\n",
      "[5]\ttrain-error:0.131726+0.00361833\ttrain-res:0.767223+0.0113593\ttest-error:0.134025+0.0071521\ttest-res:0.760135+0.00704363\n",
      "[10]\ttrain-error:0.132026+0.00355215\ttrain-res:0.769633+0.0168429\ttest-error:0.134626+0.00661101\ttest-res:0.765408+0.0112075\n",
      "[15]\ttrain-error:0.131526+0.00348416\ttrain-res:0.770514+0.0136374\ttest-error:0.133025+0.00767136\ttest-res:0.76605+0.00719716\n",
      "[20]\ttrain-error:0.131126+0.00214898\ttrain-res:0.776493+0.00983894\ttest-error:0.132626+0.00724975\ttest-res:0.7726+0.0102526\n",
      "[25]\ttrain-error:0.130276+0.0017986\ttrain-res:0.778197+0.00434467\ttest-error:0.133426+0.00738356\ttest-res:0.770963+0.00881091\n",
      "[30]\ttrain-error:0.130426+0.00214984\ttrain-res:0.779671+0.005422\ttest-error:0.132626+0.00663378\ttest-res:0.773304+0.0076092\n",
      "[35]\ttrain-error:0.129926+0.00145433\ttrain-res:0.781357+0.00378912\ttest-error:0.132426+0.00663831\ttest-res:0.774442+0.00882834\n",
      "[40]\ttrain-error:0.129826+0.00142263\ttrain-res:0.784952+0.0027929\ttest-error:0.134626+0.00673094\ttest-res:0.774524+0.00799399\n",
      "[45]\ttrain-error:0.130026+0.00149939\ttrain-res:0.784693+0.0031029\ttest-error:0.134426+0.00660408\ttest-res:0.773995+0.00896009\n",
      "[50]\ttrain-error:0.129926+0.00151833\ttrain-res:0.785964+0.00279367\ttest-error:0.133426+0.00577658\ttest-res:0.776506+0.00778349\n",
      "[55]\ttrain-error:0.130376+0.00121129\ttrain-res:0.78658+0.00224445\ttest-error:0.133226+0.00654189\ttest-res:0.778028+0.00725681\n",
      "[60]\ttrain-error:0.129526+0.00144093\ttrain-res:0.78757+0.00247867\ttest-error:0.133026+0.00615613\ttest-res:0.778321+0.00748456\n",
      "[65]\ttrain-error:0.129626+0.00163331\ttrain-res:0.78765+0.00261958\ttest-error:0.133626+0.00584451\ttest-res:0.777808+0.00746144\n",
      "[70]\ttrain-error:0.129676+0.00168432\ttrain-res:0.787499+0.00243395\ttest-error:0.133026+0.00611525\ttest-res:0.778519+0.0065946\n",
      "[75]\ttrain-error:0.129826+0.00111058\ttrain-res:0.787223+0.00237246\ttest-error:0.132626+0.00610384\ttest-res:0.778928+0.00694004\n",
      "[80]\ttrain-error:0.129476+0.0018911\ttrain-res:0.788868+0.00107037\ttest-error:0.134026+0.00615607\ttest-res:0.778527+0.00976976\n",
      "[85]\ttrain-error:0.129926+0.00184894\ttrain-res:0.789831+0.00178566\ttest-error:0.134426+0.00603859\ttest-res:0.779461+0.00927562\n",
      "[90]\ttrain-error:0.129326+0.0016296\ttrain-res:0.789904+0.00135373\ttest-error:0.134027+0.00609505\ttest-res:0.779257+0.0105069\n",
      "[95]\ttrain-error:0.129576+0.00179652\ttrain-res:0.790636+0.00191542\ttest-error:0.134426+0.0049916\ttest-res:0.779668+0.00852829\n",
      "[100]\ttrain-error:0.129176+0.00172007\ttrain-res:0.791396+0.00236436\ttest-error:0.134426+0.0049916\ttest-res:0.779636+0.00858751\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>train-res-mean</th>\n",
       "      <th>train-res-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>test-res-mean</th>\n",
       "      <th>test-res-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131076</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.779246</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.134427</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.773977</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133327</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.764667</td>\n",
       "      <td>0.022988</td>\n",
       "      <td>0.135425</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.759417</td>\n",
       "      <td>0.016951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134077</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.758523</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.137427</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.750871</td>\n",
       "      <td>0.014318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-error-mean  train-error-std  train-res-mean  train-res-std  \\\n",
       "0          0.131076         0.001095        0.779246       0.011188   \n",
       "1          0.133327         0.004237        0.764667       0.022988   \n",
       "2          0.134077         0.004268        0.758523       0.012782   \n",
       "\n",
       "   test-error-mean  test-error-std  test-res-mean  test-res-std  \n",
       "0         0.134427        0.005203       0.773977      0.004098  \n",
       "1         0.135425        0.006117       0.759417      0.016951  \n",
       "2         0.137427        0.007087       0.750871      0.014318  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_2,label=train.label)\n",
    "xgb.cv(xgb_params,dtrain,feval=evalMetric,early_stopping_rounds=100,verbose_eval=5,num_boost_round=10000,nfold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et</th>\n",
       "      <th>rf</th>\n",
       "      <th>ada</th>\n",
       "      <th>gb</th>\n",
       "      <th>dt</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.019166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    et   rf  ada   gb   dt       lgb\n",
       "0  0.0  0.0  0.8  1.0  1.0  0.199754\n",
       "1  0.0  0.0  1.0  0.6  0.2  0.019166\n",
       "2  0.0  0.0  0.0  0.0  0.0  0.000023\n",
       "3  0.0  0.0  0.0  0.0  0.0  0.000004\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.000229"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2 = pd.DataFrame()\n",
    "test_2['et'] = et_test\n",
    "test_2['rf'] = rf_test\n",
    "test_2['ada'] = ada_test\n",
    "test_2['gb'] = gb_test\n",
    "test_2['dt'] = dt_test\n",
    "test_2['lgb'] = lgb_test\n",
    "test_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=xgb.train(xgb_params,dtrain=dtrain)\n",
    "dtest = xgb.DMatrix(test_2)\n",
    "pre=model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =pd.DataFrame({'uid':test.uid,'label':pre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=res.sort_values(by='label',ascending=False)\n",
    "res.label=res.label.map(lambda x: 1 if x>=0.5 else 0)\n",
    "res.label = res.label.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../resultB/models.csv',index=False,header=False,sep=',',columns=['uid','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
